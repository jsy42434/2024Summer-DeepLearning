{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOs+cnDvxdr3J7Q4RGy+xP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsy42434/2024Summer-DeepLearning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXmlTPksHEot",
        "outputId": "645755c8-a12e-46ff-93f9-8bc526eea806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 29 (delta 6), reused 19 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (29/29), 467.72 KiB | 8.50 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8447\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8489\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8511\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8511\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8511\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "Data_set = np.loadtxt(\"./data/ThoraricSurgery3.csv\",delimiter=\",\")\n",
        "X = Data_set[:,0:16]\n",
        "y = Data_set[:,16]\n",
        "\n",
        "model= Sequential()\n",
        "model.add(Dense(30, input_dim=16, activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=5,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인디언 당뇨병 예측\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "df = pd.read_csv(\"./data/pima-indians-diabetes3.csv\")\n",
        "\n",
        "X = df.iloc[:,0:8]\n",
        "y = df.iloc[:,8]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu',name='Dense_1'))\n",
        "model.add(Dense(8, activation='relu', name='Dense_2'))\n",
        "model.add(Dense(4, activation='relu', name='Dense_3'))\n",
        "model.add(Dense(1, activation='sigmoid', name='Dense_4'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X,y,epochs=100,batch_size=5)\n"
      ],
      "metadata": {
        "id": "z_oLa6Q2StIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8f0dde-cfaa-4749-a3c8-450dcc8b53e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense_1 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " Dense_2 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " Dense_3 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " Dense_4 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 236 (944.00 Byte)\n",
            "Trainable params: 236 (944.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "154/154 [==============================] - 1s 2ms/step - loss: 1.3153 - accuracy: 0.6159\n",
            "Epoch 2/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5677\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6497\n",
            "Epoch 4/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6471\n",
            "Epoch 5/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6562\n",
            "Epoch 6/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6562\n",
            "Epoch 7/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6562\n",
            "Epoch 8/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6602\n",
            "Epoch 9/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6549\n",
            "Epoch 10/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6602\n",
            "Epoch 11/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6589\n",
            "Epoch 12/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6706\n",
            "Epoch 13/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.6189 - accuracy: 0.6589\n",
            "Epoch 14/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6719\n",
            "Epoch 15/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.6693\n",
            "Epoch 16/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6719\n",
            "Epoch 17/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5968 - accuracy: 0.6797\n",
            "Epoch 18/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6654\n",
            "Epoch 19/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6823\n",
            "Epoch 20/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6758\n",
            "Epoch 21/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6823\n",
            "Epoch 22/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6719\n",
            "Epoch 23/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6771\n",
            "Epoch 24/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6810\n",
            "Epoch 25/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6797\n",
            "Epoch 26/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6693\n",
            "Epoch 27/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6732\n",
            "Epoch 28/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6771\n",
            "Epoch 29/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6836\n",
            "Epoch 30/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6810\n",
            "Epoch 31/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6966\n",
            "Epoch 32/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6836\n",
            "Epoch 33/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6966\n",
            "Epoch 34/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6888\n",
            "Epoch 35/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6953\n",
            "Epoch 36/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6836\n",
            "Epoch 37/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7057\n",
            "Epoch 38/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7109\n",
            "Epoch 39/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7044\n",
            "Epoch 40/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7057\n",
            "Epoch 41/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7018\n",
            "Epoch 42/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7070\n",
            "Epoch 43/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6914\n",
            "Epoch 44/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7044\n",
            "Epoch 45/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7253\n",
            "Epoch 46/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5619 - accuracy: 0.7240\n",
            "Epoch 47/100\n",
            "154/154 [==============================] - 1s 3ms/step - loss: 0.5563 - accuracy: 0.7253\n",
            "Epoch 48/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5573 - accuracy: 0.7201\n",
            "Epoch 49/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5549 - accuracy: 0.7188\n",
            "Epoch 50/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5559 - accuracy: 0.7279\n",
            "Epoch 51/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7188\n",
            "Epoch 52/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.6992\n",
            "Epoch 53/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7305\n",
            "Epoch 54/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7253\n",
            "Epoch 55/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7214\n",
            "Epoch 56/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7357\n",
            "Epoch 57/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7253\n",
            "Epoch 58/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7344\n",
            "Epoch 59/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7279\n",
            "Epoch 60/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7370\n",
            "Epoch 61/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7383\n",
            "Epoch 62/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7318\n",
            "Epoch 63/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7266\n",
            "Epoch 64/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7122\n",
            "Epoch 65/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7292\n",
            "Epoch 66/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7370\n",
            "Epoch 67/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7253\n",
            "Epoch 68/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7396\n",
            "Epoch 69/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7357\n",
            "Epoch 70/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7422\n",
            "Epoch 71/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7161\n",
            "Epoch 72/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7279\n",
            "Epoch 73/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7227\n",
            "Epoch 74/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7266\n",
            "Epoch 75/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7188\n",
            "Epoch 76/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7448\n",
            "Epoch 77/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7240\n",
            "Epoch 78/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7344\n",
            "Epoch 79/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7318\n",
            "Epoch 80/100\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7292\n",
            "Epoch 81/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5258 - accuracy: 0.7461\n",
            "Epoch 82/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5194 - accuracy: 0.7383\n",
            "Epoch 83/100\n",
            "154/154 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.7513\n",
            "Epoch 84/100\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.5215 - accuracy: 0.7370\n",
            "Epoch 85/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7513\n",
            "Epoch 86/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7487\n",
            "Epoch 87/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7448\n",
            "Epoch 88/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7487\n",
            "Epoch 90/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7448\n",
            "Epoch 91/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7565\n",
            "Epoch 92/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7461\n",
            "Epoch 93/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7552\n",
            "Epoch 94/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7461\n",
            "Epoch 95/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7448\n",
            "Epoch 96/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7305\n",
            "Epoch 97/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7253\n",
            "Epoch 98/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7383\n",
            "Epoch 99/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7409\n",
            "Epoch 100/100\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#아이리스 꽃 분류\n",
        "#다중 분류를 해야 하는경우\n",
        "#원-핫 인코딩: 문자열을 숫자로 바꾸는 것\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "df = pd.read_csv(\"./data/iris3.csv\")\n",
        "\n",
        "X = df.iloc[:,0:4]\n",
        "y = df.iloc[:,4]\n",
        "\n",
        "y=pd.get_dummies(y)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=4, activation='relu',name='Dense_1'))\n",
        "model.add(Dense(8, activation='relu', name='Dense_2'))\n",
        "model.add(Dense(3, activation='softmax', name='Dense_3'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X,y,epochs=100,batch_size=5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6-gAfj4hhcH",
        "outputId": "fc01ed6f-514e-477d-c144-ee9b156d16c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense_1 (Dense)             (None, 12)                60        \n",
            "                                                                 \n",
            " Dense_2 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " Dense_3 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191 (764.00 Byte)\n",
            "Trainable params: 191 (764.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 2ms/step - loss: 1.5368 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.2582 - accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1668 - accuracy: 0.3467\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1324 - accuracy: 0.3400\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0962 - accuracy: 0.3267\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.0653 - accuracy: 0.4000\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.0268 - accuracy: 0.5067\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.9882 - accuracy: 0.6400\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.6800\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6800\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.8608 - accuracy: 0.8200\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.8171 - accuracy: 0.7200\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.7740 - accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.6933\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.7400\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.7800\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.8467\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.8733\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7733\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7667\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.9067\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8667\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8800\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.9200\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8867\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.9800\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.9600\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.9467\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.9600\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.9533\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.9600\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.9533\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.9400\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.9733\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.9800\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.9667\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.9733\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.9667\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9667\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9667\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9733\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9800\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9800\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9733\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.2309 - accuracy: 0.9800\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9800\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9800\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2058 - accuracy: 0.9733\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9733\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9800\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9600\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9800\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9800\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9733\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9733\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9800\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9800\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9733\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9800\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9800\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9733\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9800\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9733\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9667\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9800\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9667\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9800\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9467\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1198 - accuracy: 0.9733\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9733\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9800\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9800\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9800\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9667\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9733\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9800\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9800\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9667\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9800\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9733\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9667\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9800\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9733\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9733\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9800\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9733\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9800\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9800\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9667\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9667\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9800\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9733\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9733\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9800\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9667\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9733\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9733\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#광물분\n",
        "#테스트셋과 학습셋으로 나누어 과적합 방지\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "df = pd.read_csv(\"./data/sonar3.csv\")\n",
        "\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=60, activation='relu',name='Dense_1'))\n",
        "model.add(Dense(10, activation='relu', name='Dense_2'))\n",
        "model.add(Dense(1, activation='sigmoid', name='Dense_3'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs=200,batch_size=10)\n",
        "\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print('Test accuracy',score[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSlhbdlNlls-",
        "outputId": "068c6b93-1592-43a8-e3d2-4e86f95fd455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n",
            "Epoch 1/200\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.6898 - accuracy: 0.5625\n",
            "Epoch 2/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5972\n",
            "Epoch 3/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5972\n",
            "Epoch 4/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6042\n",
            "Epoch 5/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.6111\n",
            "Epoch 6/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6042\n",
            "Epoch 7/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6181\n",
            "Epoch 8/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6250\n",
            "Epoch 9/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6528\n",
            "Epoch 10/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6597\n",
            "Epoch 11/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6806\n",
            "Epoch 12/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6944\n",
            "Epoch 13/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7083\n",
            "Epoch 14/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7014\n",
            "Epoch 15/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7292\n",
            "Epoch 16/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7431\n",
            "Epoch 17/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7431\n",
            "Epoch 18/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7639\n",
            "Epoch 19/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7569\n",
            "Epoch 20/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7847\n",
            "Epoch 21/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7778\n",
            "Epoch 22/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7917\n",
            "Epoch 23/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7917\n",
            "Epoch 24/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7917\n",
            "Epoch 25/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.8125\n",
            "Epoch 26/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7778\n",
            "Epoch 27/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8264\n",
            "Epoch 28/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7986\n",
            "Epoch 29/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8056\n",
            "Epoch 30/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8194\n",
            "Epoch 31/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8264\n",
            "Epoch 32/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8264\n",
            "Epoch 33/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8333\n",
            "Epoch 34/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8194\n",
            "Epoch 35/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8264\n",
            "Epoch 36/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 37/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8472\n",
            "Epoch 38/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8542\n",
            "Epoch 39/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8472\n",
            "Epoch 40/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8542\n",
            "Epoch 41/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8264\n",
            "Epoch 42/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8542\n",
            "Epoch 43/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8750\n",
            "Epoch 44/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8333\n",
            "Epoch 45/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7986\n",
            "Epoch 46/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8611\n",
            "Epoch 47/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8472\n",
            "Epoch 48/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8681\n",
            "Epoch 49/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8611\n",
            "Epoch 50/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8264\n",
            "Epoch 51/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8333\n",
            "Epoch 52/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8542\n",
            "Epoch 53/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8681\n",
            "Epoch 54/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8542\n",
            "Epoch 55/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8542\n",
            "Epoch 56/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8194\n",
            "Epoch 57/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8681\n",
            "Epoch 58/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8681\n",
            "Epoch 59/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8542\n",
            "Epoch 60/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8750\n",
            "Epoch 61/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8681\n",
            "Epoch 62/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8750\n",
            "Epoch 63/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8403\n",
            "Epoch 64/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8958\n",
            "Epoch 65/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8681\n",
            "Epoch 66/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8750\n",
            "Epoch 67/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8889\n",
            "Epoch 68/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8750\n",
            "Epoch 69/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8889\n",
            "Epoch 70/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8958\n",
            "Epoch 71/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8750\n",
            "Epoch 72/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8819\n",
            "Epoch 73/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8889\n",
            "Epoch 74/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8819\n",
            "Epoch 75/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8889\n",
            "Epoch 76/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8819\n",
            "Epoch 77/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8889\n",
            "Epoch 78/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8958\n",
            "Epoch 79/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8958\n",
            "Epoch 80/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8958\n",
            "Epoch 81/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8958\n",
            "Epoch 82/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8958\n",
            "Epoch 83/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.9097\n",
            "Epoch 84/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8958\n",
            "Epoch 85/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.9028\n",
            "Epoch 86/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8958\n",
            "Epoch 87/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.9028\n",
            "Epoch 88/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8958\n",
            "Epoch 89/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8958\n",
            "Epoch 90/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9167\n",
            "Epoch 91/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.9167\n",
            "Epoch 92/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9097\n",
            "Epoch 93/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9097\n",
            "Epoch 94/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9028\n",
            "Epoch 95/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9167\n",
            "Epoch 96/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9097\n",
            "Epoch 97/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9097\n",
            "Epoch 98/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9167\n",
            "Epoch 99/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9236\n",
            "Epoch 100/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9167\n",
            "Epoch 101/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9097\n",
            "Epoch 102/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9167\n",
            "Epoch 103/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9236\n",
            "Epoch 104/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9236\n",
            "Epoch 105/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9306\n",
            "Epoch 106/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9236\n",
            "Epoch 107/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9236\n",
            "Epoch 108/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9236\n",
            "Epoch 109/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9306\n",
            "Epoch 110/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9375\n",
            "Epoch 111/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9306\n",
            "Epoch 112/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9306\n",
            "Epoch 113/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9236\n",
            "Epoch 114/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9375\n",
            "Epoch 115/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9236\n",
            "Epoch 116/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9236\n",
            "Epoch 117/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9236\n",
            "Epoch 118/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9306\n",
            "Epoch 119/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9444\n",
            "Epoch 120/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9375\n",
            "Epoch 121/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9375\n",
            "Epoch 122/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9375\n",
            "Epoch 123/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9444\n",
            "Epoch 124/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9444\n",
            "Epoch 125/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9375\n",
            "Epoch 126/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9375\n",
            "Epoch 127/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9375\n",
            "Epoch 128/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9375\n",
            "Epoch 129/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9375\n",
            "Epoch 130/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9514\n",
            "Epoch 131/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9375\n",
            "Epoch 132/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9375\n",
            "Epoch 133/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9375\n",
            "Epoch 134/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9444\n",
            "Epoch 135/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9514\n",
            "Epoch 136/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9444\n",
            "Epoch 137/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9514\n",
            "Epoch 138/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9653\n",
            "Epoch 139/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9444\n",
            "Epoch 140/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9444\n",
            "Epoch 141/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9583\n",
            "Epoch 142/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9444\n",
            "Epoch 143/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9722\n",
            "Epoch 144/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9514\n",
            "Epoch 145/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9583\n",
            "Epoch 146/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9722\n",
            "Epoch 147/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9722\n",
            "Epoch 148/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9514\n",
            "Epoch 149/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9792\n",
            "Epoch 150/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9792\n",
            "Epoch 151/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9583\n",
            "Epoch 152/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9722\n",
            "Epoch 153/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9722\n",
            "Epoch 154/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9514\n",
            "Epoch 155/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9861\n",
            "Epoch 156/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9792\n",
            "Epoch 157/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9722\n",
            "Epoch 158/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9861\n",
            "Epoch 159/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9792\n",
            "Epoch 160/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.9861\n",
            "Epoch 161/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.9861\n",
            "Epoch 162/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.9861\n",
            "Epoch 163/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9861\n",
            "Epoch 164/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9861\n",
            "Epoch 165/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9792\n",
            "Epoch 166/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9861\n",
            "Epoch 167/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9861\n",
            "Epoch 168/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9861\n",
            "Epoch 169/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9861\n",
            "Epoch 170/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9861\n",
            "Epoch 171/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9861\n",
            "Epoch 172/200\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.9861\n",
            "Epoch 173/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9861\n",
            "Epoch 174/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9861\n",
            "Epoch 175/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9861\n",
            "Epoch 176/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9722\n",
            "Epoch 177/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9792\n",
            "Epoch 178/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9722\n",
            "Epoch 179/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9792\n",
            "Epoch 180/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9861\n",
            "Epoch 181/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9861\n",
            "Epoch 182/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9861\n",
            "Epoch 183/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9861\n",
            "Epoch 184/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9861\n",
            "Epoch 185/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9861\n",
            "Epoch 186/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9861\n",
            "Epoch 187/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9931\n",
            "Epoch 188/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9861\n",
            "Epoch 189/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9861\n",
            "Epoch 190/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9861\n",
            "Epoch 191/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9583\n",
            "Epoch 192/200\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9861\n",
            "Epoch 193/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0876 - accuracy: 0.9861\n",
            "Epoch 194/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9861\n",
            "Epoch 195/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9861\n",
            "Epoch 196/200\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9861\n",
            "Epoch 197/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9861\n",
            "Epoch 198/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9861\n",
            "Epoch 199/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9861\n",
            "Epoch 200/200\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9861\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4638 - accuracy: 0.8254\n",
            "Test accuracy 0.8253968358039856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k곂 교차검증 06.28\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "df = pd.read_csv(\"./data/sonar3.csv\")\n",
        "\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "k=5\n",
        "\n",
        "kfold = KFold(n_splits=k, shuffle=True)\n",
        "acc_score = []\n",
        "\n",
        "def model_fn():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(24, input_dim=60, activation='relu',name='Dense_1'))\n",
        "  model.add(Dense(10, activation='relu', name='Dense_2'))\n",
        "  model.add(Dense(1, activation='sigmoid', name='Dense_3'))\n",
        "  return model\n",
        "\n",
        "for train_index, test_index in kfold.split(X):\n",
        "  X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  model = model_fn()\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(X_train,y_train,epochs=200,batch_size=10)\n",
        "  accuracy = model.evaluate(X_test,y_test)[1]\n",
        "  acc_score.append(accuracy)\n",
        "\n",
        "avg_acc_score = sum(acc_score)/k\n",
        "print('정확도: ',acc_score)\n",
        "print('정확도 평균',avg_acc_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_sr9IaQnUeQ",
        "outputId": "449fc8cb-d8e2-44d7-da47-837d7f7ed564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.6811 - accuracy: 0.5758\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5758\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.5879\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6182\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6848\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7030\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7152\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7212\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7333\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7394\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7333\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7333\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7939\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7697\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7879\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7697\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8121\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8061\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8061\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8182\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8121\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8182\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8364\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8242\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8303\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8485\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8061\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8667\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8424\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8667\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8606\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8606\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8485\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8727\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8788\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8667\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8970\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8909\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8909\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9030\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8667\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.9091\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9212\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.9212\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8970\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8970\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9212\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9091\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9273\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9273\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9273\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9273\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9212\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9515\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9515\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9212\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9394\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9636\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9212\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9455\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9333\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9455\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9455\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9697\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9576\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9636\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.9576\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9576\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9697\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9818\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9576\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9515\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9697\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9818\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9636\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9818\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9758\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9758\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9818\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9818\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9697\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9758\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9636\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9758\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9879\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9758\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9879\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9818\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9818\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9758\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9879\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9879\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9818\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9879\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9879\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9879\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9879\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9939\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9939\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9879\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9939\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9939\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9939\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9939\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9879\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9939\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9939\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9939\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9939\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9939\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9939\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9939\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x787b35f66ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5734 - accuracy: 0.8333\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.6967 - accuracy: 0.4848\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6182\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6788\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.6727\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6970\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7152\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7030\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7212\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7273\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7273\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7576\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8000\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8000\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.8061\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7939\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8242\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.8303\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8182\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8485\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8364\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8303\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8303\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8424\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8242\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8364\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8364\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8364\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8606\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8364\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8606\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8545\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8303\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8848\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8667\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8485\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8727\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8788\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8667\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8909\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8848\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8848\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.9030\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8970\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8909\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8848\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.9152\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.9152\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.9091\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2638 - accuracy: 0.9030\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2715 - accuracy: 0.9030\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2597 - accuracy: 0.9152\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8970\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.9091\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9091\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9212\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.9091\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9091\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9152\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9212\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9212\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9212\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9273\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9273\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9333\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9273\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9333\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9273\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9273\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2008 - accuracy: 0.9394\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9273\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9394\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9394\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9333\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9455\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9394\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9576\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9576\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9576\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9333\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9636\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9515\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9636\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9576\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9576\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9636\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9697\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9515\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9394\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9636\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9697\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9455\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9758\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9455\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9515\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9576\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9636\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9697\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9697\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9636\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9697\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9697\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9758\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9697\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9818\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9697\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9697\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9758\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9758\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9758\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9697\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9758\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9758\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9818\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9758\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9818\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9818\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9758\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9818\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9879\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9879\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9879\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9879\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9879\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9879\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9879\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9818\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9576\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9939\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9879\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9939\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9939\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9939\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9939\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9879\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9939\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9939\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9939\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9939\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9879\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9939\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9939\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9879\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9939\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9939\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9939\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9879\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9939\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9879\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9939\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9939\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9939\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9939\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9939\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9939\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9939\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9939\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9939\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9939\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9939\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9939\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9939\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9939\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9939\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9939\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9939\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9939\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9939\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9939\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9939\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9939\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9939\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9939\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5901 - accuracy: 0.7857\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5060\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6988\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7349\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.7530\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7530\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.7470\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7470\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7530\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7651\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7590\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7711\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7952\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8012\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7892\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8012\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7711\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8012\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8012\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8133\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8193\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8193\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8253\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8434\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8373\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8373\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8313\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8494\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8494\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8554\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8554\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8735\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8855\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8675\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8795\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8855\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8735\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8855\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8675\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8855\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8855\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8795\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8976\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8916\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8976\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8976\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8916\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8795\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8916\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.9036\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8976\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8916\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.8976\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9036\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.8916\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.8976\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9157\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.9096\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9217\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9036\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9217\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9036\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9217\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9217\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9277\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9277\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2123 - accuracy: 0.9277\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9096\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9096\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9277\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9277\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9217\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9337\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9277\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9277\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9458\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9337\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9518\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.9398\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9398\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9337\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9458\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9398\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9458\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9518\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9458\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 0.9518\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9458\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9458\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9458\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9518\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9458\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9518\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9518\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9578\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9458\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9639\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9518\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9699\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9639\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9518\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9699\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9699\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9578\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9699\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9759\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9759\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9639\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9699\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9819\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9759\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9699\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9639\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9819\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9699\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9880\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9759\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9819\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9819\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9759\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9819\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9819\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9819\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9759\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9759\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9819\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9759\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9819\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9819\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0720 - accuracy: 0.9819\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.9880\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9819\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9819\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9819\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9819\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9819\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9880\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9819\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9699\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9819\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9819\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9880\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9759\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9699\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9880\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9819\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9880\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9880\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9880\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9880\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9940\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9880\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9880\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9880\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9940\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0442 - accuracy: 0.9940\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9880\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9880\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9940\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9940\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9940\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9880\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9940\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9940\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9940\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9940\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9940\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9880\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9940\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9940\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9940\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9940\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9940\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9940\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9940\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9940\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9940\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9940\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9940\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9940\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0162 - accuracy: 0.7561\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5120\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6265\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6145\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6325\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6627\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6807\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7108\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7530\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7349\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7349\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7410\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7831\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8253\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7771\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7952\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.8072\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8193\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8193\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8373\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8434\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8554\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8133\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8193\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8253\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8554\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8554\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8313\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8554\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8373\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8434\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8373\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8554\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8434\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8735\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8494\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8735\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8795\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8795\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8735\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8855\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8795\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8735\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8855\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8795\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8795\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8916\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8855\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8795\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8916\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8976\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8976\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8976\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.9157\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8855\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8614\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8976\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8976\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8976\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8916\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9036\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9096\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8916\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9217\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2417 - accuracy: 0.9096\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9096\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9036\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9217\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9096\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9217\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9096\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9277\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9277\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9337\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9217\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9337\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9337\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9277\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9157\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9398\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9398\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9398\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9337\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9398\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9398\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9458\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9518\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9398\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9578\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9458\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9518\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9458\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9458\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9518\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9398\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9578\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9578\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9578\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9578\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9458\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9518\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9518\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9578\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9458\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9578\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9639\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9639\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9639\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9639\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9578\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9639\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9639\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9639\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9639\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9639\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9639\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9639\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9639\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9518\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9639\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9639\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9639\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9639\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9639\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9699\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9639\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9759\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9699\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9699\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9639\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9699\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9699\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9699\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9699\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9699\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9699\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9819\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9699\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9759\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9759\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9880\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9699\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9759\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9819\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9880\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9759\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9819\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9819\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9880\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9880\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9759\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9880\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9880\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9819\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9880\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9880\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9880\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9880\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9819\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9880\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9880\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9880\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9880\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9880\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9880\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9880\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9880\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9880\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9880\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9880\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9880\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9880\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9880\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9880\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9880\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9880\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9880\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9880\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9880\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9880\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9880\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9880\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9880\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9880\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9880\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9880\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9880\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9880\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9880\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9880\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9880\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9880\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9880\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9880\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9880\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9880\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9880\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9880\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9880\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9880\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9880\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2300 - accuracy: 0.9268\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5723\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.6386\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6747\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6988\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.7349\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7470\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7349\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7229\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7952\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7831\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8012\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7651\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7952\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7590\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7892\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8012\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8072\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7892\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7952\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8012\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7952\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8012\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8133\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8072\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8133\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8193\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8193\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8253\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8313\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8193\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8434\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8253\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8434\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8253\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8494\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8554\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8554\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8133\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8253\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8614\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8133\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8373\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8494\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8675\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8373\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8614\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8313\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.3136 - accuracy: 0.8735\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8855\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8795\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8795\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8855\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8916\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8855\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8916\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8735\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8916\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8675\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8614\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8916\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8916\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8795\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.9036\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.9036\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9096\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9036\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9157\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9096\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9096\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.8795\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.8976\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9337\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9036\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9277\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9277\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.8976\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9217\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9277\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9217\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9217\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9277\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9337\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9277\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9217\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9277\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9157\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9398\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1928 - accuracy: 0.9337\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9458\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9458\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9578\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9458\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9458\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9518\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9458\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9518\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9458\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9458\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9458\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9518\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9578\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9518\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9277\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.8735\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9518\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9639\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9578\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9639\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9518\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9458\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9578\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9578\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9578\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9639\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9639\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9578\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9639\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9518\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9639\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9578\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9578\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9578\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9639\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9639\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.9639\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9639\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9699\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9639\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9759\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9639\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9639\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9699\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9699\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9819\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0935 - accuracy: 0.9819\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9578\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9819\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9759\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9819\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9759\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9759\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9699\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9759\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9880\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9819\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9819\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9880\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9759\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9880\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9819\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9819\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9880\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9819\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9940\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9940\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9819\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9880\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9880\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9880\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9940\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9940\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9940\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9940\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9880\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9940\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9940\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.8780\n",
            "정확도:  [0.8333333134651184, 0.7857142686843872, 0.7560975551605225, 0.9268292784690857, 0.8780487775802612]\n",
            "정확도 평균 0.836004638671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 검증셋과 학습 자동중단\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath = './data/model/Ch14-4-bestmodel.hdf5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verboss=0, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs=2000,batch_size=500,validation_split=0.25,verbose=1,callbacks=[early_stopping_callback,checkpointer])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL48UlgrvDwH",
        "outputId": "76d919db-ecdb-441b-d3a8-adcf18463ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0514 - accuracy: 0.9907 - val_loss: 0.0590 - val_accuracy: 0.9722\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0514 - accuracy: 0.9907 - val_loss: 0.0591 - val_accuracy: 0.9722\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0513 - accuracy: 0.9907 - val_loss: 0.0592 - val_accuracy: 0.9722\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0512 - accuracy: 0.9907 - val_loss: 0.0593 - val_accuracy: 0.9722\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 67ms/step - loss: 0.0511 - accuracy: 0.9907 - val_loss: 0.0594 - val_accuracy: 0.9722\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0511 - accuracy: 0.9907 - val_loss: 0.0595 - val_accuracy: 0.9722\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0510 - accuracy: 0.9907 - val_loss: 0.0596 - val_accuracy: 0.9722\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0509 - accuracy: 0.9907 - val_loss: 0.0596 - val_accuracy: 0.9722\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0509 - accuracy: 0.9907 - val_loss: 0.0597 - val_accuracy: 0.9722\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0508 - accuracy: 0.9907 - val_loss: 0.0598 - val_accuracy: 0.9722\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0507 - accuracy: 0.9907 - val_loss: 0.0599 - val_accuracy: 0.9722\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0506 - accuracy: 0.9907 - val_loss: 0.0600 - val_accuracy: 0.9722\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0506 - accuracy: 0.9907 - val_loss: 0.0601 - val_accuracy: 0.9722\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0505 - accuracy: 0.9907 - val_loss: 0.0602 - val_accuracy: 0.9722\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0504 - accuracy: 0.9907 - val_loss: 0.0603 - val_accuracy: 0.9722\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0503 - accuracy: 0.9907 - val_loss: 0.0604 - val_accuracy: 0.9722\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0503 - accuracy: 0.9907 - val_loss: 0.0605 - val_accuracy: 0.9722\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0502 - accuracy: 0.9907 - val_loss: 0.0606 - val_accuracy: 0.9722\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0501 - accuracy: 0.9907 - val_loss: 0.0607 - val_accuracy: 0.9722\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0501 - accuracy: 0.9907 - val_loss: 0.0607 - val_accuracy: 0.9722\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0500 - accuracy: 0.9907 - val_loss: 0.0608 - val_accuracy: 0.9722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#주택가격 예측하기\n",
        "#데이터 전처리 하는 방법\n",
        "#결측치 채우기, 속성별 관련도 추출하기\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!git clone https://github.com/taehojo/data.git\n",
        "\n",
        "df = pd.read_csv(\"./data/house_train.csv\")\n",
        "\n",
        "df = pd.get_dummies(df)\n",
        "\n",
        "df = df.fillna(df.mean())\n",
        "\n",
        "df_corr = df.corr()\n",
        "\n",
        "df_corr_sort = df_corr.sort_values(by='SalePrice',ascending=False)\n",
        "\n",
        "cols_train = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF']\n",
        "\n",
        "X_train_pre = df[cols_train]\n",
        "\n",
        "y = df['SalePrice'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre,y,test_size=0.2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath = './data/model/Ch15-house.hdf5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verboss=0, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs=2000,batch_size=32,validation_split=0.25,callbacks=[early_stopping_callback,checkpointer])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L723y-LAy1Yr",
        "outputId": "370c10db-d74c-4b13-9468-c384449a34dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                60        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 30)                330       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1671 (6.53 KB)\n",
            "Trainable params: 1671 (6.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "28/28 [==============================] - 2s 20ms/step - loss: 38959902720.0000 - val_loss: 40539549696.0000\n",
            "Epoch 2/2000\n",
            "16/28 [================>.............] - ETA: 0s - loss: 38862045184.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 0s 8ms/step - loss: 38833102848.0000 - val_loss: 40403886080.0000\n",
            "Epoch 3/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 38676615168.0000 - val_loss: 40187944960.0000\n",
            "Epoch 4/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 38410379264.0000 - val_loss: 39810879488.0000\n",
            "Epoch 5/2000\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 37941678080.0000 - val_loss: 39175016448.0000\n",
            "Epoch 6/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 37148217344.0000 - val_loss: 38050062336.0000\n",
            "Epoch 7/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 35675426816.0000 - val_loss: 35747291136.0000\n",
            "Epoch 8/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 32635793408.0000 - val_loss: 31334316032.0000\n",
            "Epoch 9/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 27384127488.0000 - val_loss: 24331538432.0000\n",
            "Epoch 10/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 19745064960.0000 - val_loss: 15177110528.0000\n",
            "Epoch 11/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 10988253184.0000 - val_loss: 6839079936.0000\n",
            "Epoch 12/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 4684476928.0000 - val_loss: 2585359872.0000\n",
            "Epoch 13/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 2511598848.0000 - val_loss: 1859429376.0000\n",
            "Epoch 14/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2254528256.0000 - val_loss: 1849852160.0000\n",
            "Epoch 15/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2244810240.0000 - val_loss: 1844862976.0000\n",
            "Epoch 16/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2243005952.0000 - val_loss: 1838949760.0000\n",
            "Epoch 17/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2235667456.0000 - val_loss: 1834977280.0000\n",
            "Epoch 18/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2230619904.0000 - val_loss: 1830517376.0000\n",
            "Epoch 19/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2229559808.0000 - val_loss: 1825582720.0000\n",
            "Epoch 20/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2218859008.0000 - val_loss: 1821080704.0000\n",
            "Epoch 21/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2222836480.0000 - val_loss: 1815642368.0000\n",
            "Epoch 22/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2210025984.0000 - val_loss: 1811418880.0000\n",
            "Epoch 23/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2213312000.0000 - val_loss: 1808203776.0000\n",
            "Epoch 24/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2200501248.0000 - val_loss: 1803535616.0000\n",
            "Epoch 25/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2197366528.0000 - val_loss: 1798683008.0000\n",
            "Epoch 26/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2196010752.0000 - val_loss: 1794769664.0000\n",
            "Epoch 27/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2188213504.0000 - val_loss: 1795163904.0000\n",
            "Epoch 28/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2184349952.0000 - val_loss: 1787251840.0000\n",
            "Epoch 29/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2177801728.0000 - val_loss: 1783038720.0000\n",
            "Epoch 30/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2177744128.0000 - val_loss: 1778974336.0000\n",
            "Epoch 31/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2173300224.0000 - val_loss: 1775258752.0000\n",
            "Epoch 32/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2164758784.0000 - val_loss: 1774084608.0000\n",
            "Epoch 33/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2161820416.0000 - val_loss: 1768759936.0000\n",
            "Epoch 34/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2163321856.0000 - val_loss: 1766177408.0000\n",
            "Epoch 35/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2156686336.0000 - val_loss: 1764011136.0000\n",
            "Epoch 36/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2159212544.0000 - val_loss: 1760011904.0000\n",
            "Epoch 37/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2152013824.0000 - val_loss: 1756131456.0000\n",
            "Epoch 38/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2157944064.0000 - val_loss: 1753873408.0000\n",
            "Epoch 39/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2143175808.0000 - val_loss: 1750739200.0000\n",
            "Epoch 40/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2142828032.0000 - val_loss: 1748611072.0000\n",
            "Epoch 41/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2136610176.0000 - val_loss: 1745726464.0000\n",
            "Epoch 42/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2138312064.0000 - val_loss: 1742778496.0000\n",
            "Epoch 43/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2130361984.0000 - val_loss: 1740719360.0000\n",
            "Epoch 44/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2128779520.0000 - val_loss: 1739459328.0000\n",
            "Epoch 45/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2130421376.0000 - val_loss: 1736046848.0000\n",
            "Epoch 46/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2126130304.0000 - val_loss: 1734124544.0000\n",
            "Epoch 47/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2129437696.0000 - val_loss: 1732073984.0000\n",
            "Epoch 48/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2124852096.0000 - val_loss: 1729710336.0000\n",
            "Epoch 49/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2116816000.0000 - val_loss: 1730590208.0000\n",
            "Epoch 50/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2117031680.0000 - val_loss: 1725741696.0000\n",
            "Epoch 51/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2112765312.0000 - val_loss: 1723715712.0000\n",
            "Epoch 52/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2110085888.0000 - val_loss: 1722722432.0000\n",
            "Epoch 53/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2114160384.0000 - val_loss: 1720589696.0000\n",
            "Epoch 54/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2109873664.0000 - val_loss: 1718877952.0000\n",
            "Epoch 55/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2111793664.0000 - val_loss: 1717220608.0000\n",
            "Epoch 56/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2118013824.0000 - val_loss: 1715887616.0000\n",
            "Epoch 57/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2101570432.0000 - val_loss: 1714150144.0000\n",
            "Epoch 58/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2103547136.0000 - val_loss: 1714353280.0000\n",
            "Epoch 59/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2099958784.0000 - val_loss: 1712694144.0000\n",
            "Epoch 60/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2106889984.0000 - val_loss: 1710542464.0000\n",
            "Epoch 61/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2111480192.0000 - val_loss: 1708632576.0000\n",
            "Epoch 62/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2093002112.0000 - val_loss: 1709634432.0000\n",
            "Epoch 63/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2092321920.0000 - val_loss: 1706224128.0000\n",
            "Epoch 64/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2095856896.0000 - val_loss: 1705343616.0000\n",
            "Epoch 65/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2087615488.0000 - val_loss: 1705163392.0000\n",
            "Epoch 66/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2087875072.0000 - val_loss: 1702866688.0000\n",
            "Epoch 67/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2084732032.0000 - val_loss: 1702959104.0000\n",
            "Epoch 68/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2084972800.0000 - val_loss: 1700402688.0000\n",
            "Epoch 69/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2085555584.0000 - val_loss: 1700504064.0000\n",
            "Epoch 70/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2083472128.0000 - val_loss: 1699002368.0000\n",
            "Epoch 71/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2079707904.0000 - val_loss: 1698374400.0000\n",
            "Epoch 72/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2085369856.0000 - val_loss: 1698191360.0000\n",
            "Epoch 73/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2085641344.0000 - val_loss: 1698084224.0000\n",
            "Epoch 74/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2080506112.0000 - val_loss: 1699339392.0000\n",
            "Epoch 75/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2081738496.0000 - val_loss: 1696972800.0000\n",
            "Epoch 76/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2079440768.0000 - val_loss: 1695940096.0000\n",
            "Epoch 77/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2079592704.0000 - val_loss: 1696366208.0000\n",
            "Epoch 78/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2091068928.0000 - val_loss: 1694243456.0000\n",
            "Epoch 79/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2068496128.0000 - val_loss: 1703528960.0000\n",
            "Epoch 80/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2080459136.0000 - val_loss: 1691943936.0000\n",
            "Epoch 81/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2078035200.0000 - val_loss: 1691329408.0000\n",
            "Epoch 82/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2077256576.0000 - val_loss: 1694055808.0000\n",
            "Epoch 83/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2072985728.0000 - val_loss: 1692893568.0000\n",
            "Epoch 84/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2069055360.0000 - val_loss: 1690103552.0000\n",
            "Epoch 85/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2071423488.0000 - val_loss: 1689741312.0000\n",
            "Epoch 86/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2071337984.0000 - val_loss: 1688958208.0000\n",
            "Epoch 87/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2074750464.0000 - val_loss: 1689498496.0000\n",
            "Epoch 88/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2077131904.0000 - val_loss: 1689196544.0000\n",
            "Epoch 89/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2079519872.0000 - val_loss: 1687664384.0000\n",
            "Epoch 90/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2071466240.0000 - val_loss: 1689702016.0000\n",
            "Epoch 91/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2087159808.0000 - val_loss: 1689158784.0000\n",
            "Epoch 92/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2066907136.0000 - val_loss: 1686731392.0000\n",
            "Epoch 93/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2069858176.0000 - val_loss: 1686111488.0000\n",
            "Epoch 94/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2070195712.0000 - val_loss: 1685751296.0000\n",
            "Epoch 95/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2075283456.0000 - val_loss: 1685517184.0000\n",
            "Epoch 96/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2069122432.0000 - val_loss: 1685730816.0000\n",
            "Epoch 97/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2070854912.0000 - val_loss: 1684768768.0000\n",
            "Epoch 98/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2063938304.0000 - val_loss: 1684836096.0000\n",
            "Epoch 99/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2067532928.0000 - val_loss: 1685092096.0000\n",
            "Epoch 100/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2065046272.0000 - val_loss: 1684057728.0000\n",
            "Epoch 101/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2065764480.0000 - val_loss: 1687138688.0000\n",
            "Epoch 102/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2067770368.0000 - val_loss: 1685537408.0000\n",
            "Epoch 103/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2066646144.0000 - val_loss: 1683583104.0000\n",
            "Epoch 104/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2070654720.0000 - val_loss: 1684987904.0000\n",
            "Epoch 105/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2069176704.0000 - val_loss: 1683495296.0000\n",
            "Epoch 106/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2061770880.0000 - val_loss: 1683747456.0000\n",
            "Epoch 107/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2063645056.0000 - val_loss: 1683716608.0000\n",
            "Epoch 108/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2062865920.0000 - val_loss: 1683808000.0000\n",
            "Epoch 109/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2067401344.0000 - val_loss: 1682276224.0000\n",
            "Epoch 110/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2070709120.0000 - val_loss: 1682230784.0000\n",
            "Epoch 111/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2065593216.0000 - val_loss: 1683165568.0000\n",
            "Epoch 112/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2065038208.0000 - val_loss: 1682290560.0000\n",
            "Epoch 113/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2062627584.0000 - val_loss: 1682800000.0000\n",
            "Epoch 114/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059996544.0000 - val_loss: 1682985728.0000\n",
            "Epoch 115/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2058501376.0000 - val_loss: 1682011648.0000\n",
            "Epoch 116/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2059124992.0000 - val_loss: 1681363456.0000\n",
            "Epoch 117/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2067854208.0000 - val_loss: 1680750080.0000\n",
            "Epoch 118/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2060892544.0000 - val_loss: 1684025856.0000\n",
            "Epoch 119/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2059652352.0000 - val_loss: 1681209088.0000\n",
            "Epoch 120/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2064920064.0000 - val_loss: 1683836288.0000\n",
            "Epoch 121/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2063773696.0000 - val_loss: 1680270720.0000\n",
            "Epoch 122/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2056004224.0000 - val_loss: 1685100672.0000\n",
            "Epoch 123/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2063675264.0000 - val_loss: 1680212224.0000\n",
            "Epoch 124/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2063702272.0000 - val_loss: 1681421568.0000\n",
            "Epoch 125/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2054486016.0000 - val_loss: 1683711360.0000\n",
            "Epoch 126/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2060216832.0000 - val_loss: 1681980416.0000\n",
            "Epoch 127/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2068982144.0000 - val_loss: 1679678080.0000\n",
            "Epoch 128/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2058590592.0000 - val_loss: 1686067072.0000\n",
            "Epoch 129/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2056717824.0000 - val_loss: 1679356288.0000\n",
            "Epoch 130/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2062579840.0000 - val_loss: 1679496704.0000\n",
            "Epoch 131/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2055633280.0000 - val_loss: 1680260096.0000\n",
            "Epoch 132/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059880960.0000 - val_loss: 1680876032.0000\n",
            "Epoch 133/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2059010176.0000 - val_loss: 1679063296.0000\n",
            "Epoch 134/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2058266368.0000 - val_loss: 1679227904.0000\n",
            "Epoch 135/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2055871104.0000 - val_loss: 1679796992.0000\n",
            "Epoch 136/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2056140672.0000 - val_loss: 1680434688.0000\n",
            "Epoch 137/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2055623296.0000 - val_loss: 1679029504.0000\n",
            "Epoch 138/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2067618560.0000 - val_loss: 1684860032.0000\n",
            "Epoch 139/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2053209600.0000 - val_loss: 1678753664.0000\n",
            "Epoch 140/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2061579904.0000 - val_loss: 1678274816.0000\n",
            "Epoch 141/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2064567296.0000 - val_loss: 1678831872.0000\n",
            "Epoch 142/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2061934080.0000 - val_loss: 1678776064.0000\n",
            "Epoch 143/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2057851520.0000 - val_loss: 1682252416.0000\n",
            "Epoch 144/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2064193024.0000 - val_loss: 1679475200.0000\n",
            "Epoch 145/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2068144000.0000 - val_loss: 1678017920.0000\n",
            "Epoch 146/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2056421632.0000 - val_loss: 1677772160.0000\n",
            "Epoch 147/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2057438080.0000 - val_loss: 1679141376.0000\n",
            "Epoch 148/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2054736000.0000 - val_loss: 1677889152.0000\n",
            "Epoch 149/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2055680000.0000 - val_loss: 1677804928.0000\n",
            "Epoch 150/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2061558528.0000 - val_loss: 1677884288.0000\n",
            "Epoch 151/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2057507200.0000 - val_loss: 1677236096.0000\n",
            "Epoch 152/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2068809600.0000 - val_loss: 1677162752.0000\n",
            "Epoch 153/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2066173696.0000 - val_loss: 1680960384.0000\n",
            "Epoch 154/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2060535680.0000 - val_loss: 1680242688.0000\n",
            "Epoch 155/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059125760.0000 - val_loss: 1678826752.0000\n",
            "Epoch 156/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2082690048.0000 - val_loss: 1677537920.0000\n",
            "Epoch 157/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2065616512.0000 - val_loss: 1681126656.0000\n",
            "Epoch 158/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052315008.0000 - val_loss: 1681373440.0000\n",
            "Epoch 159/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2055853568.0000 - val_loss: 1676639872.0000\n",
            "Epoch 160/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059722112.0000 - val_loss: 1685046656.0000\n",
            "Epoch 161/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2057886336.0000 - val_loss: 1676841856.0000\n",
            "Epoch 162/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2056530176.0000 - val_loss: 1676572160.0000\n",
            "Epoch 163/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2054728576.0000 - val_loss: 1677508352.0000\n",
            "Epoch 164/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2051391872.0000 - val_loss: 1677294592.0000\n",
            "Epoch 165/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2055062272.0000 - val_loss: 1679152000.0000\n",
            "Epoch 166/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 2074611456.0000 - val_loss: 1676010880.0000\n",
            "Epoch 167/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2055542656.0000 - val_loss: 1676615168.0000\n",
            "Epoch 168/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2057115904.0000 - val_loss: 1683150080.0000\n",
            "Epoch 169/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2063905152.0000 - val_loss: 1677742976.0000\n",
            "Epoch 170/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2055782784.0000 - val_loss: 1676539648.0000\n",
            "Epoch 171/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2052449024.0000 - val_loss: 1676231680.0000\n",
            "Epoch 172/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2050220160.0000 - val_loss: 1677404160.0000\n",
            "Epoch 173/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2055919232.0000 - val_loss: 1675813632.0000\n",
            "Epoch 174/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2054973312.0000 - val_loss: 1675739520.0000\n",
            "Epoch 175/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2055455744.0000 - val_loss: 1676386176.0000\n",
            "Epoch 176/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2052767104.0000 - val_loss: 1676356736.0000\n",
            "Epoch 177/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2050975872.0000 - val_loss: 1675967616.0000\n",
            "Epoch 178/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2052985856.0000 - val_loss: 1675416576.0000\n",
            "Epoch 179/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2059234304.0000 - val_loss: 1680355968.0000\n",
            "Epoch 180/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2050762624.0000 - val_loss: 1675566592.0000\n",
            "Epoch 181/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2058467456.0000 - val_loss: 1675191808.0000\n",
            "Epoch 182/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2056672384.0000 - val_loss: 1674864000.0000\n",
            "Epoch 183/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2053681152.0000 - val_loss: 1676175872.0000\n",
            "Epoch 184/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2058292480.0000 - val_loss: 1677360640.0000\n",
            "Epoch 185/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2050975488.0000 - val_loss: 1675776896.0000\n",
            "Epoch 186/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2050299904.0000 - val_loss: 1676046592.0000\n",
            "Epoch 187/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2057414144.0000 - val_loss: 1674151680.0000\n",
            "Epoch 188/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059002880.0000 - val_loss: 1675000064.0000\n",
            "Epoch 189/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2055363968.0000 - val_loss: 1678611712.0000\n",
            "Epoch 190/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2055519616.0000 - val_loss: 1674809728.0000\n",
            "Epoch 191/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2051482368.0000 - val_loss: 1673887616.0000\n",
            "Epoch 192/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2049593088.0000 - val_loss: 1673665792.0000\n",
            "Epoch 193/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2056389632.0000 - val_loss: 1674169472.0000\n",
            "Epoch 194/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2061329664.0000 - val_loss: 1680900864.0000\n",
            "Epoch 195/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2047996544.0000 - val_loss: 1673840000.0000\n",
            "Epoch 196/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052707072.0000 - val_loss: 1674143232.0000\n",
            "Epoch 197/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2057137920.0000 - val_loss: 1676556032.0000\n",
            "Epoch 198/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2050935680.0000 - val_loss: 1674282752.0000\n",
            "Epoch 199/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2049438976.0000 - val_loss: 1673150336.0000\n",
            "Epoch 200/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2049911936.0000 - val_loss: 1677334656.0000\n",
            "Epoch 201/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2049369728.0000 - val_loss: 1673787776.0000\n",
            "Epoch 202/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2053960192.0000 - val_loss: 1672840832.0000\n",
            "Epoch 203/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2055621888.0000 - val_loss: 1672646912.0000\n",
            "Epoch 204/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2054318336.0000 - val_loss: 1672909312.0000\n",
            "Epoch 205/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2046735104.0000 - val_loss: 1672693504.0000\n",
            "Epoch 206/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2049447424.0000 - val_loss: 1675274112.0000\n",
            "Epoch 207/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2051886464.0000 - val_loss: 1673425536.0000\n",
            "Epoch 208/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2057043712.0000 - val_loss: 1678618112.0000\n",
            "Epoch 209/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052254336.0000 - val_loss: 1675752832.0000\n",
            "Epoch 210/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2052422656.0000 - val_loss: 1675814784.0000\n",
            "Epoch 211/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2050978432.0000 - val_loss: 1672061952.0000\n",
            "Epoch 212/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2047540480.0000 - val_loss: 1673500416.0000\n",
            "Epoch 213/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2074376192.0000 - val_loss: 1672788608.0000\n",
            "Epoch 214/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2048867968.0000 - val_loss: 1672505600.0000\n",
            "Epoch 215/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2051986176.0000 - val_loss: 1672740224.0000\n",
            "Epoch 216/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2044987904.0000 - val_loss: 1672939136.0000\n",
            "Epoch 217/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052100224.0000 - val_loss: 1674827520.0000\n",
            "Epoch 218/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2050985984.0000 - val_loss: 1672063872.0000\n",
            "Epoch 219/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2047599616.0000 - val_loss: 1671702656.0000\n",
            "Epoch 220/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2054656896.0000 - val_loss: 1672044800.0000\n",
            "Epoch 221/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2056522496.0000 - val_loss: 1671924864.0000\n",
            "Epoch 222/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2046836352.0000 - val_loss: 1671593472.0000\n",
            "Epoch 223/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2046869376.0000 - val_loss: 1674744448.0000\n",
            "Epoch 224/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2055608960.0000 - val_loss: 1672059520.0000\n",
            "Epoch 225/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2086717312.0000 - val_loss: 1671880064.0000\n",
            "Epoch 226/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2062095744.0000 - val_loss: 1670875392.0000\n",
            "Epoch 227/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2045497216.0000 - val_loss: 1672690432.0000\n",
            "Epoch 228/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2058057216.0000 - val_loss: 1671207552.0000\n",
            "Epoch 229/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2055531520.0000 - val_loss: 1678899712.0000\n",
            "Epoch 230/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2068246784.0000 - val_loss: 1676723584.0000\n",
            "Epoch 231/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2048688384.0000 - val_loss: 1672445696.0000\n",
            "Epoch 232/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052723584.0000 - val_loss: 1672724992.0000\n",
            "Epoch 233/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2045080704.0000 - val_loss: 1671585280.0000\n",
            "Epoch 234/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2044042496.0000 - val_loss: 1670821120.0000\n",
            "Epoch 235/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2045439616.0000 - val_loss: 1671052160.0000\n",
            "Epoch 236/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2061946624.0000 - val_loss: 1671129728.0000\n",
            "Epoch 237/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2048918656.0000 - val_loss: 1670736128.0000\n",
            "Epoch 238/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2043067264.0000 - val_loss: 1672675328.0000\n",
            "Epoch 239/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2043778432.0000 - val_loss: 1674857984.0000\n",
            "Epoch 240/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2042414208.0000 - val_loss: 1672193664.0000\n",
            "Epoch 241/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2043321984.0000 - val_loss: 1671172992.0000\n",
            "Epoch 242/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052367872.0000 - val_loss: 1673601664.0000\n",
            "Epoch 243/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2038588416.0000 - val_loss: 1673701632.0000\n",
            "Epoch 244/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2044466048.0000 - val_loss: 1671032064.0000\n",
            "Epoch 245/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2049244672.0000 - val_loss: 1670768768.0000\n",
            "Epoch 246/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2040504192.0000 - val_loss: 1670787712.0000\n",
            "Epoch 247/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2044618368.0000 - val_loss: 1669957120.0000\n",
            "Epoch 248/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2039898880.0000 - val_loss: 1671343104.0000\n",
            "Epoch 249/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2042697472.0000 - val_loss: 1673915264.0000\n",
            "Epoch 250/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2045795712.0000 - val_loss: 1671498880.0000\n",
            "Epoch 251/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 2046321024.0000 - val_loss: 1669744000.0000\n",
            "Epoch 252/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2038052736.0000 - val_loss: 1672103680.0000\n",
            "Epoch 253/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2041387392.0000 - val_loss: 1671738112.0000\n",
            "Epoch 254/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2052770688.0000 - val_loss: 1670432896.0000\n",
            "Epoch 255/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2039096704.0000 - val_loss: 1673053184.0000\n",
            "Epoch 256/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2049742848.0000 - val_loss: 1669971968.0000\n",
            "Epoch 257/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2050753664.0000 - val_loss: 1670414976.0000\n",
            "Epoch 258/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2046996352.0000 - val_loss: 1670330752.0000\n",
            "Epoch 259/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2042491648.0000 - val_loss: 1670238592.0000\n",
            "Epoch 260/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2043884160.0000 - val_loss: 1669944704.0000\n",
            "Epoch 261/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2042994176.0000 - val_loss: 1672121472.0000\n",
            "Epoch 262/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2038126080.0000 - val_loss: 1670423552.0000\n",
            "Epoch 263/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2036718336.0000 - val_loss: 1669023616.0000\n",
            "Epoch 264/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2041779072.0000 - val_loss: 1668608384.0000\n",
            "Epoch 265/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2042659712.0000 - val_loss: 1668419968.0000\n",
            "Epoch 266/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2044195712.0000 - val_loss: 1668853376.0000\n",
            "Epoch 267/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2040498944.0000 - val_loss: 1668475392.0000\n",
            "Epoch 268/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 2039490816.0000 - val_loss: 1668074240.0000\n",
            "Epoch 269/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2039876864.0000 - val_loss: 1667732992.0000\n",
            "Epoch 270/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2041558784.0000 - val_loss: 1670581120.0000\n",
            "Epoch 271/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2033956608.0000 - val_loss: 1668229504.0000\n",
            "Epoch 272/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2046758272.0000 - val_loss: 1668596224.0000\n",
            "Epoch 273/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2040980736.0000 - val_loss: 1668249984.0000\n",
            "Epoch 274/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2033992704.0000 - val_loss: 1670307328.0000\n",
            "Epoch 275/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2033767552.0000 - val_loss: 1669141376.0000\n",
            "Epoch 276/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2041029504.0000 - val_loss: 1668626816.0000\n",
            "Epoch 277/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2041328512.0000 - val_loss: 1667942656.0000\n",
            "Epoch 278/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2059747968.0000 - val_loss: 1668806016.0000\n",
            "Epoch 279/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2038101248.0000 - val_loss: 1667803264.0000\n",
            "Epoch 280/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2039007488.0000 - val_loss: 1668460544.0000\n",
            "Epoch 281/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2036436480.0000 - val_loss: 1666581120.0000\n",
            "Epoch 282/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2034685824.0000 - val_loss: 1670323712.0000\n",
            "Epoch 283/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2038179968.0000 - val_loss: 1667271936.0000\n",
            "Epoch 284/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2033820032.0000 - val_loss: 1667630464.0000\n",
            "Epoch 285/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2032909184.0000 - val_loss: 1667243520.0000\n",
            "Epoch 286/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2048023680.0000 - val_loss: 1670294656.0000\n",
            "Epoch 287/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2034542336.0000 - val_loss: 1667790464.0000\n",
            "Epoch 288/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2039208704.0000 - val_loss: 1666273920.0000\n",
            "Epoch 289/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2040414720.0000 - val_loss: 1670700160.0000\n",
            "Epoch 290/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2033885568.0000 - val_loss: 1666367104.0000\n",
            "Epoch 291/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2041347968.0000 - val_loss: 1667005696.0000\n",
            "Epoch 292/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2043391232.0000 - val_loss: 1665940480.0000\n",
            "Epoch 293/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2046805888.0000 - val_loss: 1666428672.0000\n",
            "Epoch 294/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2030192768.0000 - val_loss: 1668062080.0000\n",
            "Epoch 295/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2040079360.0000 - val_loss: 1666077952.0000\n",
            "Epoch 296/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2039057024.0000 - val_loss: 1666976896.0000\n",
            "Epoch 297/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2032163456.0000 - val_loss: 1664901632.0000\n",
            "Epoch 298/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2034258688.0000 - val_loss: 1671593216.0000\n",
            "Epoch 299/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2031185280.0000 - val_loss: 1665468032.0000\n",
            "Epoch 300/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2031697408.0000 - val_loss: 1666640768.0000\n",
            "Epoch 301/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2031560448.0000 - val_loss: 1666282240.0000\n",
            "Epoch 302/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2037982464.0000 - val_loss: 1670331904.0000\n",
            "Epoch 303/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2026696960.0000 - val_loss: 1664909312.0000\n",
            "Epoch 304/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2035932416.0000 - val_loss: 1666636288.0000\n",
            "Epoch 305/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2028925696.0000 - val_loss: 1665005952.0000\n",
            "Epoch 306/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2036360960.0000 - val_loss: 1664584960.0000\n",
            "Epoch 307/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2027407872.0000 - val_loss: 1665025920.0000\n",
            "Epoch 308/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2044910080.0000 - val_loss: 1666440320.0000\n",
            "Epoch 309/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2036703104.0000 - val_loss: 1665314048.0000\n",
            "Epoch 310/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2034008064.0000 - val_loss: 1664095360.0000\n",
            "Epoch 311/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2035590144.0000 - val_loss: 1664876672.0000\n",
            "Epoch 312/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2037460096.0000 - val_loss: 1667892608.0000\n",
            "Epoch 313/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2035503872.0000 - val_loss: 1663564544.0000\n",
            "Epoch 314/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2025457920.0000 - val_loss: 1664029696.0000\n",
            "Epoch 315/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2033626880.0000 - val_loss: 1663969408.0000\n",
            "Epoch 316/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2025149824.0000 - val_loss: 1670943360.0000\n",
            "Epoch 317/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2048826240.0000 - val_loss: 1664955392.0000\n",
            "Epoch 318/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2027207552.0000 - val_loss: 1665587968.0000\n",
            "Epoch 319/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2025780480.0000 - val_loss: 1663441280.0000\n",
            "Epoch 320/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2027808512.0000 - val_loss: 1663023104.0000\n",
            "Epoch 321/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2022624128.0000 - val_loss: 1664012032.0000\n",
            "Epoch 322/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2028222080.0000 - val_loss: 1666517504.0000\n",
            "Epoch 323/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2026733696.0000 - val_loss: 1663695488.0000\n",
            "Epoch 324/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2032401792.0000 - val_loss: 1667743488.0000\n",
            "Epoch 325/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2023482624.0000 - val_loss: 1662417152.0000\n",
            "Epoch 326/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2026193920.0000 - val_loss: 1662644480.0000\n",
            "Epoch 327/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2022850432.0000 - val_loss: 1663471360.0000\n",
            "Epoch 328/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2027849472.0000 - val_loss: 1662025216.0000\n",
            "Epoch 329/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2017443456.0000 - val_loss: 1663844352.0000\n",
            "Epoch 330/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2040370432.0000 - val_loss: 1664223488.0000\n",
            "Epoch 331/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2030213504.0000 - val_loss: 1664730368.0000\n",
            "Epoch 332/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2030807424.0000 - val_loss: 1664457088.0000\n",
            "Epoch 333/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2021009664.0000 - val_loss: 1662347776.0000\n",
            "Epoch 334/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2020854144.0000 - val_loss: 1662160640.0000\n",
            "Epoch 335/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2034758272.0000 - val_loss: 1664746880.0000\n",
            "Epoch 336/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2029356416.0000 - val_loss: 1660434816.0000\n",
            "Epoch 337/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2035446528.0000 - val_loss: 1661519744.0000\n",
            "Epoch 338/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2033935744.0000 - val_loss: 1661268864.0000\n",
            "Epoch 339/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2022811776.0000 - val_loss: 1661205120.0000\n",
            "Epoch 340/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2027432576.0000 - val_loss: 1660355968.0000\n",
            "Epoch 341/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2023906816.0000 - val_loss: 1660030720.0000\n",
            "Epoch 342/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2038104704.0000 - val_loss: 1667640576.0000\n",
            "Epoch 343/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2018147712.0000 - val_loss: 1663268480.0000\n",
            "Epoch 344/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2017420544.0000 - val_loss: 1659893248.0000\n",
            "Epoch 345/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2014122496.0000 - val_loss: 1662781568.0000\n",
            "Epoch 346/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2023984896.0000 - val_loss: 1661262336.0000\n",
            "Epoch 347/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2018300544.0000 - val_loss: 1659765248.0000\n",
            "Epoch 348/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2022420352.0000 - val_loss: 1659244160.0000\n",
            "Epoch 349/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2014770432.0000 - val_loss: 1661394944.0000\n",
            "Epoch 350/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2016164864.0000 - val_loss: 1664141440.0000\n",
            "Epoch 351/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2010510592.0000 - val_loss: 1659750784.0000\n",
            "Epoch 352/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2015358464.0000 - val_loss: 1658531328.0000\n",
            "Epoch 353/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2012485120.0000 - val_loss: 1659770496.0000\n",
            "Epoch 354/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2024650624.0000 - val_loss: 1660086528.0000\n",
            "Epoch 355/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2015233536.0000 - val_loss: 1659216000.0000\n",
            "Epoch 356/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2012275968.0000 - val_loss: 1672538240.0000\n",
            "Epoch 357/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2014273024.0000 - val_loss: 1659573120.0000\n",
            "Epoch 358/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2009490432.0000 - val_loss: 1660545664.0000\n",
            "Epoch 359/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2017948544.0000 - val_loss: 1659800576.0000\n",
            "Epoch 360/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2014651904.0000 - val_loss: 1660066816.0000\n",
            "Epoch 361/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2010620544.0000 - val_loss: 1662295552.0000\n",
            "Epoch 362/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2008139392.0000 - val_loss: 1659356416.0000\n",
            "Epoch 363/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2025807872.0000 - val_loss: 1658936320.0000\n",
            "Epoch 364/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2023178112.0000 - val_loss: 1659535872.0000\n",
            "Epoch 365/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2007038592.0000 - val_loss: 1657641088.0000\n",
            "Epoch 366/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2007100160.0000 - val_loss: 1658636288.0000\n",
            "Epoch 367/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2008373632.0000 - val_loss: 1657344000.0000\n",
            "Epoch 368/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2009624832.0000 - val_loss: 1658889472.0000\n",
            "Epoch 369/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2007837696.0000 - val_loss: 1663379712.0000\n",
            "Epoch 370/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2015061760.0000 - val_loss: 1660390784.0000\n",
            "Epoch 371/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2006892032.0000 - val_loss: 1657429888.0000\n",
            "Epoch 372/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2003264256.0000 - val_loss: 1657157888.0000\n",
            "Epoch 373/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2007946112.0000 - val_loss: 1661920896.0000\n",
            "Epoch 374/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2011315968.0000 - val_loss: 1657972992.0000\n",
            "Epoch 375/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2022745856.0000 - val_loss: 1657566208.0000\n",
            "Epoch 376/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2005408000.0000 - val_loss: 1658440832.0000\n",
            "Epoch 377/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2009826048.0000 - val_loss: 1660724224.0000\n",
            "Epoch 378/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2009760384.0000 - val_loss: 1656150528.0000\n",
            "Epoch 379/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2000839808.0000 - val_loss: 1656913664.0000\n",
            "Epoch 380/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2001039104.0000 - val_loss: 1658028160.0000\n",
            "Epoch 381/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1999304448.0000 - val_loss: 1658022400.0000\n",
            "Epoch 382/2000\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 2008477312.0000 - val_loss: 1655438976.0000\n",
            "Epoch 383/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2003844480.0000 - val_loss: 1657133696.0000\n",
            "Epoch 384/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1996824448.0000 - val_loss: 1655284224.0000\n",
            "Epoch 385/2000\n",
            "28/28 [==============================] - 0s 17ms/step - loss: 2005937664.0000 - val_loss: 1656391168.0000\n",
            "Epoch 386/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 2003073152.0000 - val_loss: 1657260288.0000\n",
            "Epoch 387/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2002456064.0000 - val_loss: 1661488256.0000\n",
            "Epoch 388/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1999751680.0000 - val_loss: 1655839872.0000\n",
            "Epoch 389/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2000188032.0000 - val_loss: 1658132480.0000\n",
            "Epoch 390/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 2009621760.0000 - val_loss: 1655559040.0000\n",
            "Epoch 391/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1996495744.0000 - val_loss: 1656339968.0000\n",
            "Epoch 392/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1997652096.0000 - val_loss: 1653722624.0000\n",
            "Epoch 393/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1992774400.0000 - val_loss: 1658614016.0000\n",
            "Epoch 394/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1997102592.0000 - val_loss: 1655429632.0000\n",
            "Epoch 395/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2004591616.0000 - val_loss: 1655721344.0000\n",
            "Epoch 396/2000\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 2007165440.0000 - val_loss: 1655089792.0000\n",
            "Epoch 397/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 1994520576.0000 - val_loss: 1655832192.0000\n",
            "Epoch 398/2000\n",
            "28/28 [==============================] - 1s 19ms/step - loss: 1995817216.0000 - val_loss: 1655217024.0000\n",
            "Epoch 399/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2004912640.0000 - val_loss: 1655013504.0000\n",
            "Epoch 400/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1990128128.0000 - val_loss: 1655860992.0000\n",
            "Epoch 401/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1994897792.0000 - val_loss: 1655842432.0000\n",
            "Epoch 402/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1991506560.0000 - val_loss: 1653772160.0000\n",
            "Epoch 403/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1989394944.0000 - val_loss: 1652906624.0000\n",
            "Epoch 404/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1999124352.0000 - val_loss: 1652586112.0000\n",
            "Epoch 405/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1988717056.0000 - val_loss: 1655951872.0000\n",
            "Epoch 406/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1996919168.0000 - val_loss: 1652119168.0000\n",
            "Epoch 407/2000\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 1988535680.0000 - val_loss: 1655852032.0000\n",
            "Epoch 408/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 1987256832.0000 - val_loss: 1652465152.0000\n",
            "Epoch 409/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1991480832.0000 - val_loss: 1660241152.0000\n",
            "Epoch 410/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 2006693760.0000 - val_loss: 1653975296.0000\n",
            "Epoch 411/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1998189696.0000 - val_loss: 1654440576.0000\n",
            "Epoch 412/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1996380544.0000 - val_loss: 1652020096.0000\n",
            "Epoch 413/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1984244224.0000 - val_loss: 1660921856.0000\n",
            "Epoch 414/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1986280832.0000 - val_loss: 1652163968.0000\n",
            "Epoch 415/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1987014912.0000 - val_loss: 1651966592.0000\n",
            "Epoch 416/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1982601088.0000 - val_loss: 1651716864.0000\n",
            "Epoch 417/2000\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 1991609472.0000 - val_loss: 1656430080.0000\n",
            "Epoch 418/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 1982001152.0000 - val_loss: 1651804160.0000\n",
            "Epoch 419/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1991868160.0000 - val_loss: 1652006400.0000\n",
            "Epoch 420/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1981182336.0000 - val_loss: 1652829312.0000\n",
            "Epoch 421/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1987885184.0000 - val_loss: 1651868160.0000\n",
            "Epoch 422/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1980317312.0000 - val_loss: 1653520512.0000\n",
            "Epoch 423/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1988432256.0000 - val_loss: 1654829952.0000\n",
            "Epoch 424/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1985288064.0000 - val_loss: 1656653952.0000\n",
            "Epoch 425/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1986985344.0000 - val_loss: 1653338496.0000\n",
            "Epoch 426/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1979506048.0000 - val_loss: 1652704000.0000\n",
            "Epoch 427/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1988248064.0000 - val_loss: 1651584128.0000\n",
            "Epoch 428/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1985038592.0000 - val_loss: 1652636672.0000\n",
            "Epoch 429/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1989131136.0000 - val_loss: 1650450048.0000\n",
            "Epoch 430/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 2001318272.0000 - val_loss: 1660534912.0000\n",
            "Epoch 431/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1978469120.0000 - val_loss: 1649782144.0000\n",
            "Epoch 432/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1975492608.0000 - val_loss: 1651745408.0000\n",
            "Epoch 433/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1975249536.0000 - val_loss: 1650441088.0000\n",
            "Epoch 434/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1984993280.0000 - val_loss: 1650823168.0000\n",
            "Epoch 435/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1976284032.0000 - val_loss: 1652334592.0000\n",
            "Epoch 436/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1977583104.0000 - val_loss: 1649892224.0000\n",
            "Epoch 437/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1974777344.0000 - val_loss: 1650340736.0000\n",
            "Epoch 438/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1971412608.0000 - val_loss: 1652895104.0000\n",
            "Epoch 439/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1969396096.0000 - val_loss: 1649719936.0000\n",
            "Epoch 440/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1978027392.0000 - val_loss: 1650138624.0000\n",
            "Epoch 441/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1975533184.0000 - val_loss: 1651193088.0000\n",
            "Epoch 442/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1973076224.0000 - val_loss: 1652005760.0000\n",
            "Epoch 443/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1977152896.0000 - val_loss: 1650335616.0000\n",
            "Epoch 444/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1976512000.0000 - val_loss: 1652299392.0000\n",
            "Epoch 445/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1968646656.0000 - val_loss: 1651109120.0000\n",
            "Epoch 446/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1968820480.0000 - val_loss: 1650208384.0000\n",
            "Epoch 447/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1977624448.0000 - val_loss: 1649708032.0000\n",
            "Epoch 448/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1972202880.0000 - val_loss: 1650260224.0000\n",
            "Epoch 449/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1968366848.0000 - val_loss: 1654859648.0000\n",
            "Epoch 450/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1972128512.0000 - val_loss: 1649656192.0000\n",
            "Epoch 451/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1968713984.0000 - val_loss: 1651349760.0000\n",
            "Epoch 452/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1971425920.0000 - val_loss: 1649223040.0000\n",
            "Epoch 453/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1968884736.0000 - val_loss: 1651295488.0000\n",
            "Epoch 454/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1978027648.0000 - val_loss: 1651716096.0000\n",
            "Epoch 455/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1965714816.0000 - val_loss: 1655857792.0000\n",
            "Epoch 456/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1979525504.0000 - val_loss: 1650887552.0000\n",
            "Epoch 457/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1964080256.0000 - val_loss: 1651723392.0000\n",
            "Epoch 458/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1968833408.0000 - val_loss: 1652151168.0000\n",
            "Epoch 459/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1968493696.0000 - val_loss: 1649876480.0000\n",
            "Epoch 460/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1963209728.0000 - val_loss: 1647968768.0000\n",
            "Epoch 461/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1970259328.0000 - val_loss: 1653587072.0000\n",
            "Epoch 462/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1961540096.0000 - val_loss: 1648609536.0000\n",
            "Epoch 463/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1962467456.0000 - val_loss: 1651265408.0000\n",
            "Epoch 464/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1967256704.0000 - val_loss: 1650711680.0000\n",
            "Epoch 465/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1959632000.0000 - val_loss: 1649576448.0000\n",
            "Epoch 466/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1956049408.0000 - val_loss: 1648632192.0000\n",
            "Epoch 467/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1962749184.0000 - val_loss: 1649126656.0000\n",
            "Epoch 468/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1960802816.0000 - val_loss: 1648075264.0000\n",
            "Epoch 469/2000\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 1965446784.0000 - val_loss: 1649700480.0000\n",
            "Epoch 470/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1974612992.0000 - val_loss: 1649075968.0000\n",
            "Epoch 471/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1957353600.0000 - val_loss: 1660241152.0000\n",
            "Epoch 472/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1954740224.0000 - val_loss: 1647781632.0000\n",
            "Epoch 473/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1974727296.0000 - val_loss: 1647139328.0000\n",
            "Epoch 474/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1965154176.0000 - val_loss: 1652084480.0000\n",
            "Epoch 475/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1967811712.0000 - val_loss: 1650114688.0000\n",
            "Epoch 476/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1952670464.0000 - val_loss: 1647790080.0000\n",
            "Epoch 477/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1955557248.0000 - val_loss: 1647900416.0000\n",
            "Epoch 478/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1960096000.0000 - val_loss: 1647264768.0000\n",
            "Epoch 479/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1957398528.0000 - val_loss: 1647195776.0000\n",
            "Epoch 480/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1957003776.0000 - val_loss: 1647577600.0000\n",
            "Epoch 481/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1955174144.0000 - val_loss: 1647965056.0000\n",
            "Epoch 482/2000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 1953170816.0000 - val_loss: 1647640192.0000\n",
            "Epoch 483/2000\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1951790208.0000 - val_loss: 1647444480.0000\n",
            "Epoch 484/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1955949056.0000 - val_loss: 1648029568.0000\n",
            "Epoch 485/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1956346240.0000 - val_loss: 1651893632.0000\n",
            "Epoch 486/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1948092672.0000 - val_loss: 1648668416.0000\n",
            "Epoch 487/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1946370560.0000 - val_loss: 1656689536.0000\n",
            "Epoch 488/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1949863936.0000 - val_loss: 1650004224.0000\n",
            "Epoch 489/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1946143488.0000 - val_loss: 1648119040.0000\n",
            "Epoch 490/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1951644416.0000 - val_loss: 1648978816.0000\n",
            "Epoch 491/2000\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1963222912.0000 - val_loss: 1647666816.0000\n",
            "Epoch 492/2000\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1957161984.0000 - val_loss: 1662895360.0000\n",
            "Epoch 493/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1954377600.0000 - val_loss: 1649176576.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손글씨 숫자 인식하기\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0],784).astype('float32')/255\n",
        "X_test = X_test.reshape(X_test.shape[0],784).astype('float32')/255\n",
        "\n",
        "y_train = to_categorical(y_train,10)\n",
        "y_test = to_categorical(y_test,10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512,input_dim=784, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "modelpath = './MNIST_MLP.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verboss=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
        "\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "WC4s_J9a_Fm9",
        "outputId": "9fa8f2c1-48de-4b28-ade6-3b9a1bf82733"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9811\n",
            "\n",
            " Test Accuracy: 0.9811\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')/255\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')/255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "modelpath = './MNIST_CNN.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verboss=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
        "\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mNQt99B0R4M9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "bf1a2f65-71fd-4b14-e192-50aa8f01f47d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9921\n",
            "\n",
            " Test Accuracy: 0.9921\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkZklEQVR4nO3deVxU5eIG8GdmGHYQEWURFERcL+7JRS3NUNQWabkueW9qbjfjV0ZZ2U3QtDQzM8sty+22aJtaaSaiaCnqzaXcQ0MRFVALURAYmPP7420GBoZtmJkzMzzfz+d8ZubMmXfed2aYeXjf95yjkCRJAhEREVEjopS7AkRERETWxgBEREREjQ4DEBERETU6DEBERETU6DAAERERUaPDAERERESNDgMQERERNTpOclfAFmm1Wly5cgVeXl5QKBRyV4eIiIjqQJIk3Lp1C0FBQVAqa+7jYQAy4sqVKwgJCZG7GkRERGSCS5cuITg4uMZtGICM8PLyAiBeQG9vb7OWrdFosGPHDgwePBhqtdqsZdsCts/+OXob2T775+htZPtMl5+fj5CQEP3veE0YgIzQDXt5e3tbJAC5u7vD29vbYT/YbJ99c/Q2sn32z9HbyPY1XF2mr3ASNBERETU6DEBERETU6DAAERERUaPDOUBERGRzysrKoNFojN6n0Wjg5OSEoqIilJWVWblmlsf2VU+tVkOlUpmlHgxARERkMyRJQnZ2NvLy8mrcJiAgAJcuXXLIY7WxfTXz8fFBQEBAg18bBiAiIrIZuvDTokULuLu7G/2R02q1uH37Njw9PWs92J09YvuMkyQJhYWFyM3NBQAEBgY2qB4MQEREZBPKysr04adZs2bVbqfValFSUgJXV1eHDQhsn3Fubm4AgNzcXLRo0aJBw2GO98oSEZFd0s35cXd3l7kmZMt0n4/q5ojVFQMQERHZFEec90LmY67PBwMQERERNToMQERERNToMABZWVYWcPy4H7Ky5K4JERFRzdauXQsfHx+5q2ERDEBWtGIF0LatE2bO7Iu2bZ3w0Udy14iIiBpCoVDUuMyaNcvkslUqFTZv3my2ugJAaGgoFi9ebNYy7RV3g7eSrCxg6lRAksTkLa1WgSlTgNhYIDhY5soRETmarCwgPR2IiLDol+zVq1f11zdu3IjExEScPXtWv87T09Niz00Nwx4gK0lPByTJcF1ZGXDunDz1ISKyeZIEFBTUf1m2DGjdGhg4UFwuW1b/Mip/YVcjICBAvzRp0gQKhcJg3YYNG9CxY0e4urqiQ4cOWLZsmf6xJSUliI+PR2BgIFxdXdG6dWvMmzcPANClSxcAwMMPPwyFQoHQ0FAAwC+//IJ7770XXl5e8Pb2Rs+ePfHzzz/ry/zpp59w9913w83NDSEhIXjmmWdQUFAAABgwYAAuXryI5557Tt9DZYrly5cjPDwczs7OaN++Pf773/9WeMskzJo1C61atYKLiwuCgoLwzDPP6O9ftmwZ2rdvj4CAAAQGBuKxxx4zqQ7mwB4gK4mIABQKw78plQpo21a+OhER2bTCQsBID4oSgE9dy9BqgaefFkt93L4NeHjU7zGVfPLJJ0hMTMT777+P7t274+jRo5g0aRI8PDwwduxYLFmyBN988w0+//xztGrVCpcuXcKlS5cAALt27UJERATWrFmDIUOG6A/4N2bMGHTv3h3Lly+HSqXCsWPHoFarAQDnz5/HkCFDMHfuXKxevRrXrl1DfHw84uPjsWbNGnz99dfo2rUrJk+ejEmTJpnUpk2bNuHZZ5/F4sWLERMTg++++w7jx49HcHAw7r33Xnz11Vd45513sGHDBnTu3BnZ2dn45ZdfAAA///wznnnmGaxbtw6RkZHQaDTYt29fg17jhmAAspLgYGD6dGDBAnFbpZKwcqWCw19ERA4qKSkJb7/9Nh555BEAQFhYGE6dOoWVK1di7NixyMzMREREBPr16weFQoHWrVsDEEdK9vPzA1B+3iudzMxMTJ8+HR06dAAARERE6O+bN28exowZg2nTpunvW7JkCfr374/ly5fD19cXKpUKXl5eBmXWx8KFCzFu3DhMnToVAJCQkIADBw5g4cKFuPfee5GZmYmAgADExMRArVajVatW6N27t77uHh4eeOCBByBJkr4HSy4cArOiiRPFpVpdhvT0UkyYIG99iIhsmru76ImptGjz85GXlQVtfn7V+8+eBSqfXkGlEuuNlFXt0sCjURcUFOD8+fOYMGECPD099cvcuXNx/vx5AMC4ceNw7NgxtG/fHs888wx27NhRa7kJCQmYOHEiYmJiMH/+fH1ZgBgeW7t2rcHzxcbGQqvVIiMjo0Ht0Tl9+jT69u1rsK5v3744ffo0AOAf//gH7ty5gzZt2mDSpEnYtGkTSktLAQCDBg1C69at0bZtW0yZMgWffPIJCgsLzVIvUzAAWZEucGs0KjRtKm9diIhsnkIhhqHqs7RrB3zwgQg9gLhcuVKsr085DTza8O3btwEAq1atwrFjx/TLiRMncODAAQBAjx49kJGRgTlz5uDOnTsYMWJErXNiZs2ahZMnT+L+++/Hrl270KlTJ2zatEn/nFOmTDF4vl9++QXp6ekIDw9vUHvqKiQkBGfPnsWyZcvg5uaGqVOn4p577oFGo4GXlxeOHDmCTz75BP7+/pg1axa6du2KvLw8q9StMg6BWZGnJ+DmJuHOHQVycgAHPbQCEZG8JkwQu9ieOycmWsow18Df3x9BQUH4/fffMWbMmGq38/b2xsiRIzFy5Eg89thjGDJkCP744w84OTlBrVajrKysymPatWuHdu3a4bnnnsPo0aOxZs0aPPzww+jRowdOnTqFtjVMLnV2djZaZl117NgR+/btw9ixY/Xr9u3bh06dOulvu7m54cEHH8SDDz6Ip59+Gh06dMDx48fRo0cPODk5ISYmBr1798brr78OX19f7Nq1Sz9MaE0MQFakUIheoIwMICdHgfbt5a4REZGDCg6W/Rgjs2fPxjPPPIMmTZpgyJAhKC4uxs8//4w///wTCQkJWLRoEQIDA9G9e3colUp88cUXCAgIgI+PD27fvo3Q0FCkpKSgb9++cHFxgaurK6ZPn47HHnsMYWFhyMrKwv/+9z88+uijAICXXnoJf//73xEfH4+JEyfCw8MDp06dQnJyMt5//30A4jhAe/fuxahRo+Di4qKfa1RX06dPx4gRI9C9e3fExMTg22+/xddff42dO3cCEAdOLCsrQ1RUFNzd3fHxxx/Dzc0NrVu3xnfffYfff/8d/fr1g5OTE3788UdotVq0l+nHkENgVtaihdgNLCdH5ooQEZFFTZw4ER9++CHWrFmDyMhI9O/fH2vXrkVYWBgAwMvLCwsWLECvXr1w11134cKFC9i2bRuUf81heuutt5CcnIyQkBB0794dKpUKN27cwBNPPIF27dphxIgRGDp0KGbPng1A7Dq/Z88e/Pbbb7j77rvRvXt3JCYmIigoSF+n1157DRcuXEB4eDiaN29e7zbFxcXh3XffxcKFC9G5c2esXLkSa9aswYABAwCISdurVq1C37590aVLF+zcuRPffvstmjVrBh8fH3z99deIiYnB3//+d3zwwQf47LPP0Llz5wa+0qZRSFIdD3bQiOTn56NJkya4efMmvL29zVr28OFafPONEu+9V4b4eJVZy7YFGo0G27Ztw7Bhw/S7ZjoSR28f4PhtZPtsV1FRETIyMhAWFgZXV9dqt9NqtcjPz4e3t7c+LDgStq9mNX1O6vP77XivrI0LCBB5Mztb5ooQERE1YgxAVtaihbjMzZW3HkREREOHDjXYbb7i8sYbb8hdPYviJGgr0+0Kn53dsF0siYiIGurDDz/EnTt3jN7n6+tr5dpYFwOQlekmQbMHiIiI5NayZUu5qyAbDoFZma4HKCeHPUBERERyYQCyMn//8knQ3P+OiIhIHgxAVubvLy6LihS4dUveuhARETVWDEBW5u4OuLlpAHBXeCIiIrkwAMnAx6cYAI8GTUREJBcGIBnoAhB7gIiIyJguXbrg3Xfflbsa1bpw4QIUCgWOHTsmd1VMxgAkg6ZNiwAwABER2TuFQlHjMmvWLJPK3bVrFyZNmmTeytZg3LhxiIuLs9rz2QIeB0gGHAIjIrKsrCwgPR2IiLDsSeGvXr2qv75x40YkJibi7Nmz+nWenp7665IkoaysDE5Otf/0+vn5wd3d3byVJQPsAZIBh8CIiGonSUBBQf2XZcuA1q2BgQPF5bJl9S+jrocpCQgI0C9NmjSBQqHQ3z5z5gy8vLzw/fffo2fPnnBxccFPP/2E8+fPY/jw4fD394enpyfuuusu7Ny506DcykNgCoUCH374IR5++GG4u7sjIiIC33zzjf7+P//8E2PGjEHz5s3h5uaGiIgIrFmzRn//pUuXMGLECPj4+MDX1xfDhw/HhQsXAACzZs3CunXrsGXLFn3PVWpqar3frz179qB3795wcXFBYGAgXn75ZZSWlurv//LLLxEZGQkPDw+0adMGgwcPRkFBAQAgNTUVvXv3hoeHB3x8fNC3b19cvHix3nWoD/YAyYA9QEREtSssBCp0oFSgBOBTpzK0WuDpp8VSH7dvAx4e9XtMdV5++WUsXLgQbdq0QdOmTXHp0iUMGzYMr7/+OlxcXLB+/Xo8+OCDOHv2LFq1alVtObNnz8aCBQvw1ltv4b333sOYMWNw8eJF+Pr6YubMmTh16hS+//57+Pn54dy5c/pTXGg0GsTGxiI6Oho//vgjnJycMHfuXAwZMgS//vorXnjhBZw+fRr5+fn60FTf02BcvnwZw4YNw7hx47B+/XqcOXMGkyZNgqurK2bNmoWrV69i9OjRWLBgAYYPH46rV6/i2LFjkCQJpaWliIuLw6RJk/DZZ5+hpKQEhw4dgkJh2QMGMwDJwMeHc4CIiBqL1157DYMGDdLf9vX1RdeuXfW358yZg02bNuGbb75BfHx8teWMGzcOo0ePBgC88cYbWLJkCQ4dOoQhQ4YgMzMT3bt3R69evQAAoaGh+sdt3LgRWq0WH374oT5UrFmzBj4+PkhNTcXgwYPh5uaG4uJiBOhOV1BPy5YtQ0hICN5//30oFAp06NABV65cwUsvvYTExERcvXoVpaWleOSRRxASEgJfX19ER0dDqVTijz/+wM2bN/HAAw8gPDwcANCxY0eT6lEfDEAyaNqUQ2BERLVxdxc9MZVptVrk5+fD29sbSqXhTI7Ll4GOHUXPj45KBZw6BdTntFfmnH6jCyU6t2/fxqxZs7B161Z9MLhz5w4yMzNrLKdLly766x4eHvD29kbuXyeWfOqpp/Doo4/iyJEjGDx4MOLi4tCnTx8AwC+//IJz587By8vLoLyioiKcP3/eHE3E6dOnER0dbdBr07dvX9y+fRtZWVno2rUr7rvvPkRGRmLw4MG4++678c9//hPNmjWDr68vxo0bh9jYWAwaNAgxMTEYMWIEAgMDzVK36nAOkAwqDoHxdBhERMYpFGIYqj5Lu3bABx+I0AOIy5Urxfr6lGPO0RePSmNpL7zwAjZt2oQ33ngDP/74I44dO4bIyEiUlJTUWI5ara70+iig/SvpDR06FBcvXsRzzz2HK1eu4L777sMLL7wAQASunj174tixYwbLb7/9hscff9x8Da2BSqVCcnIyvv/+e3Tq1AkffPABOnbsiIyMDACiRyotLQ19+vTBxo0b0a5dOxw4cMCidWIAkoEuAGk0wJ9/ylwZIiIHM2ECcOECsHu3uJwwQe4aGdq3bx/GjRuHhx9+GJGRkQgICNBPSG6I5s2bY+zYsfj444+xePFifPDBBwCAHj16ID09HS1atEDbtm0NliZNmgAAnJ2dUVZWZvJzd+zYEWlpaZAq/Fe/b98+eHl5Ifiv3fAUCgX69u2LWbNmYe/evXB2dsamTZv023fv3h0zZszA/v378be//Q2ffvqpyfWpCwYgGajVWvj4iA8JJ0ITEZlfcDAwYIBld4E3VUREBL7++mscO3YMv/zyCx5//HF9T46pEhMTsWXLFpw7dw4nT57Ed999p59HM2bMGPj5+WH48OH48ccfkZGRgdTUVDzzzDPIysoCIOYM/frrrzh79iyuX78OjUZTr+efOnUqLl26hP/7v//DmTNnsGXLFiQlJSEhIQFKpRIHDx7EG2+8gZ9//hmZmZn49ttvce3aNX0v0IwZM5CWloaLFy9ix44dSE9Pt/g8IAYgmehOisp5QEREjcuiRYvQtGlT9OnTBw8++CBiY2PRo0ePBpXp7OyMGTNmoEuXLrjnnnugUqmwYcMGAIC7uzv27t2LVq1a4ZFHHkHHjh0xYcIEFBUVwdvbGwAwadIktG/fHr169ULz5s2xb9++ej1/y5YtsW3bNhw6dAhdu3bFv//9b0yYMAGvvvoqAMDb2xt79+7FsGHD0KFDB7z++utYuHAhhg4dCnd3d5w5cwaPPvoo2rVrh8mTJ+Ppp5/GlClTGvSa1IaToGUSECDh7FkFAxARkYMYN24cxo0bp789YMAAgyEhndDQUOzatctg3dOV9tP/9ddf9eEEgNFy8vLy9NdfffVVfdgwJiAgAOvWrav2/ubNm2PHjh3V3l9ZaGholTr1798fhw4dMrp9x44dsX37dgCGk9gBwN/f32AozFrYAySTFi3EJYfAiIiIrM8mAtDSpUsRGhoKV1dXREVFVZsgAeDrr79Gr1694OPjAw8PD3Tr1g3//e9/DbaRJAmJiYkIDAyEm5sbYmJikJ6ebulm1EtAgEjO7AEiIiJb88Ybb8DT09PoMnToULmrZxayD4Ft3LgRCQkJWLFiBaKiorB48WLExsbi7NmzaKHrJqnA19cX//nPf9ChQwc4Ozvju+++w/jx49GiRQvExsYCABYsWIAlS5Zg3bp1CAsLw8yZMxEbG4tTp07B1dXV2k00ij1ARERkq/79739jxIgRRu9zc3Ozcm0sQ/YAtGjRIkyaNAnjx48HAKxYsQJbt27F6tWr8fLLL1fZfsCAAQa3n332Waxbtw4//fQTYmNjIUkSFi9ejFdffRXDhw8HAKxfvx7+/v7YvHkzRo0aZfE21QV7gIiIyFb5+vrW+3QY9kbWAFRSUoLDhw9jxowZ+nVKpRIxMTFIS0ur9fGSJGHXrl04e/Ys3nzzTQBARkYGsrOzERMTo9+uSZMmiIqKQlpamtEAVFxcjOLiYv3t/Px8AOL8KfXdFbA2uvKaNSsF4ISrVyVoNKU1P8iO6Npn7tfNVjh6+wDHbyPbZ7tKS0v154aqabdw3eRbSZIavPu4LWL7albxc1L5c16fz72sAej69esoKyuDv26f8L/4+/vjzJkz1T7u5s2baNmyJYqLi6FSqbBs2TL9eVay/+pSMVZmdjXdLfPmzcPs2bOrrN+xYwfczXk89AoyMg4AGIDMzGJs2/aDRZ5DTsnJyXJXwaIcvX2A47eR7bNN/v7+uHDhAnx9feHkVPNP1I0bN6xUK3mwfVWVlpbijz/+wO3bt5GSklLl/sLCwjqXJfsQmCm8vLxw7Ngx/QuQkJCANm3aVBkeq6sZM2YgISFBfzs/Px8hISEYPHiwwW6I5qDRaJCcnIzhw6Pw/PNAfr4LhgwZBqVNTEdvOF37Bg0aVOWw7Y7A0dsHOH4b2T7bptFokJOTY7CLd2WSJKGoqAiurq4WP2O4HNi+mnl4eKBNmzZGP9+6EZy6kDUA+fn5QaVSIafSTOCcnJwaz0irVCrRtm1bAEC3bt1w+vRpzJs3DwMGDNA/Licnx+BEajk5OejWrZvR8lxcXODi4lJlvVqtttgXSGCgExQKoKxMgfx8NZo3t8jTyMaSr50tcPT2AY7fRrbPNqnVaoSGhqK0tLTaUzNoNBrs3bsX99xzj122sTZsX/VUKhWcnJyqDU71KU/WAOTs7IyePXsiJSUFcXFxAMQBklJSUhAfH1/ncrRarX4OT1hYGAICApCSkqIPPPn5+Th48CCeeuopczfBZGo10KwZcP26mAjtaAGIiMhUCoWixgCnUqlQWloKV1dXhwwIbJ91yD4ElpCQgLFjx6JXr17o3bs3Fi9ejIKCAv1eYU888QRatmyJefPmARDzdXr16oXw8HAUFxdj27Zt+O9//4vly5cDEH8406ZNw9y5cxEREaHfDT4oKEgfsmxFQEB5AIqMlLs2REREjYfsAWjkyJG4du0aEhMTkZ2djW7dumH79u36ScyZmZlQVpggU1BQgKlTpyIrKwtubm7o0KEDPv74Y4wcOVK/zYsvvoiCggJMnjwZeXl56NevH7Zv324zxwDS8fcHTpzgsYCIiIisTfYABADx8fHVDnmlpqYa3J47dy7mzp1bY3kKhQKvvfYaXnvtNXNV0SJ005x4LCAiIiLrcpB9j+yTLgCxB4iIiMi6GIBkpDtUEXuAiIiIrIsBSEYcAiMiIpIHA5CMdD1AHAIjIiKyLgYgGbEHiIiISB4MQDLSBaDr14FSxzkfKhERkc1jAJJRs2aAUglIEnDtmty1ISIiajwYgGSkUgEtWojrHAYjIiKyHgYgmXEiNBERkfUxAMmME6GJiIisjwFIZjwaNBERkfUxAMmMR4MmIiKyPgYgmXEIjIiIyPoYgGTGSdBERETWxwAkM/YAERERWR8DkMw4CZqIiMj6GIBkphsC++MPoLhY3roQERE1FgxAMmvaFFCrxfXcXHnrQkRE1FgwAMlMqSw/HQaHwYiIiKyDAcgGcCI0ERGRdTEA2QBOhCYiIrIuBiAbwKNBExERWRcDkA3gEBgREZF1MQDZAB4NmoiIyLoYgGwAe4CIiIisiwHIBnASNBERkXUxANkAToImIiKyLgYgG6DrAcrPB+7ckbcuREREjQEDkA3w9gZcXMR1DoMRERFZHgOQDVAoOBGaiIjImhiAbAQnQhMREVkPA5CN4ERoIiIi62EAshEcAiMiIrIeBiAbwaNBExERWQ8DkI1gDxAREZH1MADZCE6CJiIish4GIBvBSdBERETWwwBkIzgERkREZD0MQDZC1wNUWAjcvi1vXYiIiBwdA5CN8PQEPDzEdfYCERERWRYDkA3hRGgiIiLrYACyIZwITUREZB02EYCWLl2K0NBQuLq6IioqCocOHap221WrVuHuu+9G06ZN0bRpU8TExFTZfty4cVAoFAbLkCFDLN2MBuNEaCIiIuuQPQBt3LgRCQkJSEpKwpEjR9C1a1fExsYiNzfX6PapqakYPXo0du/ejbS0NISEhGDw4MG4fPmywXZDhgzB1atX9ctnn31mjeY0CIfAiIiIrEP2ALRo0SJMmjQJ48ePR6dOnbBixQq4u7tj9erVRrf/5JNPMHXqVHTr1g0dOnTAhx9+CK1Wi5SUFIPtXFxcEBAQoF+aNm1qjeY0CIfAiIiIrMNJzicvKSnB4cOHMWPGDP06pVKJmJgYpKWl1amMwsJCaDQa+Pr6GqxPTU1FixYt0LRpUwwcOBBz585Fs2bNjJZRXFyM4uJi/e38/HwAgEajgUajqW+zaqQrz1i5zZsrADjh6lUtNJoysz6vtdTUPkfg6O0DHL+NbJ/9c/Q2sn0NL7suFJIkSWavQR1duXIFLVu2xP79+xEdHa1f/+KLL2LPnj04ePBgrWVMnToVP/zwA06ePAlXV1cAwIYNG+Du7o6wsDCcP38er7zyCjw9PZGWlgaVSlWljFmzZmH27NlV1n/66adwd3dvQAvr5+DBAMybF4WIiD/x1lt7rfa8REREjqCwsBCPP/44bt68CW9v7xq3lbUHqKHmz5+PDRs2IDU1VR9+AGDUqFH665GRkejSpQvCw8ORmpqK++67r0o5M2bMQEJCgv52fn6+fm5RbS9gfWk0GiQnJ2PQoEFQq9UG9/n5KTBvHlBc7INhw4aZ9Xmtpab2OQJHbx/g+G1k++yfo7eR7TOdbgSnLmQNQH5+flCpVMipNOs3JycHAboZwdVYuHAh5s+fj507d6JLly41btumTRv4+fnh3LlzRgOQi4sLXFxcqqxXq9UW+/AZKzs4WFzm5Cjg5KSGQmGRp7YKS752tsDR2wc4fhvZPvvn6G1k+0wrs65knQTt7OyMnj17Gkxg1k1orjgkVtmCBQswZ84cbN++Hb169ar1ebKysnDjxg0EBgaapd6WopsEXVwM3Lwpb12IiIgcmex7gSUkJGDVqlVYt24dTp8+jaeeegoFBQUYP348AOCJJ54wmCT95ptvYubMmVi9ejVCQ0ORnZ2N7Oxs3P7rBFq3b9/G9OnTceDAAVy4cAEpKSkYPnw42rZti9jYWFnaWFeurkCTJuI6d4UnIiKyHNnnAI0cORLXrl1DYmIisrOz0a1bN2zfvh3+f3WHZGZmQqksz2nLly9HSUkJHnvsMYNykpKSMGvWLKhUKvz6669Yt24d8vLyEBQUhMGDB2POnDlGh7lsjb+/6P3Jzgbat5e7NkRERI5J9gAEAPHx8YiPjzd6X2pqqsHtCxcu1FiWm5sbfvjhBzPVzPoCAoDffuOxgIiIiCxJ9iEwMsSjQRMREVkeA5CN4dGgiYiILI8ByMbwhKhERESWxwBkY3Q9QBwCIyIishwGIBvDHiAiIiLLYwCyMZwETUREZHkMQDam4hCYVitvXYiIiBwVA5CNadFCXJaWAn/8IW9diIiIHBUDkI1xdgZ8fcV1DoMRERFZBgOQDeJEaCIiIstiALJBnAhNRERkWQxANohHgyYiIrIsBiAbxCEwIiIiy2IAskE8GjQREZFlMQDZIPYAERERWRYDkA3iJGgiIiLLYgCyQZwETUREZFkMQDZI1wN07RpQViZvXYiIiBwRA5AN8vMDFApxLrDr1+WuDRERkeNhALJBTk5A8+biOofBiIiIzI8ByEZxIjQREZHlMADZKE6EJiIishwGIBvFYwERERFZDgOQjeLRoImIiCyHAchGsQeIiIjIchiAbBQnQRMREVkOA5CN4iRoIiIiy2EAslEcAiMiIrIcBiAbpesBunED0GjkrQsREZGjYQCyUc2aASqVuJ6bK29diIiIHA0DkI1SKrkrPBERkaUwANkwToQmIiKyDAYgG8aJ0ERERJbBAGTDOARGRERkGQxANow9QERERJbBAGTDeDRoIiIiy2AAsmGcBE1ERGQZDEA2jENgRERElsEAZMM4BEZERGQZDEA2TDcElpcHFBXJWhUiIiKHwgBkw3x8AGdncZ2nwyAiIjIfBiAbplBwIjQREZEl2EQAWrp0KUJDQ+Hq6oqoqCgcOnSo2m1XrVqFu+++G02bNkXTpk0RExNTZXtJkpCYmIjAwEC4ubkhJiYG6enplm6GRXAiNBERkfnJHoA2btyIhIQEJCUl4ciRI+jatStiY2ORW82YT2pqKkaPHo3du3cjLS0NISEhGDx4MC5fvqzfZsGCBViyZAlWrFiBgwcPwsPDA7GxsSiyw4k0nAhNRERkfrIHoEWLFmHSpEkYP348OnXqhBUrVsDd3R2rV682uv0nn3yCqVOnolu3bujQoQM+/PBDaLVapKSkABC9P4sXL8arr76K4cOHo0uXLli/fj2uXLmCzZs3W7Fl5sEhMCIiIvNzkvPJS0pKcPjwYcyYMUO/TqlUIiYmBmlpaXUqo7CwEBqNBr6+vgCAjIwMZGdnIyYmRr9NkyZNEBUVhbS0NIwaNapKGcXFxSguLtbfzs/PBwBoNBpoNBqT2lYdXXl1Lbd5cyUAFa5eLYNGozVrXSyhvu2zN47ePsDx28j22T9HbyPb1/Cy60LWAHT9+nWUlZXBX9fN8Rd/f3+cOXOmTmW89NJLCAoK0gee7L+6SoyVmV1NN8q8efMwe/bsKut37NgBd3f3OtWjvpKTk+u03fXrYQC64NixHGzb9j+L1MUS6to+e+Xo7QMcv41sn/1z9DayffVXWFhY521lDUANNX/+fGzYsAGpqalwdXU1uZwZM2YgISFBfzs/P18/t8jb29scVdXTaDRITk7GoEGDoFara93+zh0FVq0CFIoADBs2zKx1sYT6ts/eOHr7AMdvI9tn/xy9jWyf6XQjOHUhawDy8/ODSqVCTqUZvjk5OQjQzf6txsKFCzF//nzs3LkTXbp00a/XPS4nJweBgYEGZXbr1s1oWS4uLnBxcamyXq1WW+zDV9eyg4PFZW6uEmq17FO26sySr50tcPT2AY7fRrbP/jl6G9k+08qsK1l/UZ2dndGzZ0/9BGYA+gnN0dHR1T5uwYIFmDNnDrZv345evXoZ3BcWFoaAgACDMvPz83Hw4MEay7RVnARNRERkfrIPgSUkJGDs2LHo1asXevfujcWLF6OgoADjx48HADzxxBNo2bIl5s2bBwB48803kZiYiE8//RShoaH6eT2enp7w9PSEQqHAtGnTMHfuXERERCAsLAwzZ85EUFAQ4uLi5GqmyXQdYbdvAwUFgIeHvPUhIiJyBLIHoJEjR+LatWtITExEdnY2unXrhu3bt+snMWdmZkKpLO+oWr58OUpKSvDYY48ZlJOUlIRZs2YBAF588UUUFBRg8uTJyMvLQ79+/bB9+/YGzROSi6cn4OYG3LkjjgXUpo3cNSIiIrJ/sgcgAIiPj0d8fLzR+1JTUw1uX7hwodbyFAoFXnvtNbz22mtmqJ28FArRC5SRIYbBGICIiIgazn5m1TZiPBo0ERGReTEA2QFOhCYiIjIvBiA7wB4gIiIi82IAsgPsASIiIjIvBiA7oOsBYgAiIiIyDwYgO8AhMCIiIvNiALIDHAIjIiIyLwYgO1CxB0iS5K0LERGRI2AAsgO6HqA7d4Bbt+StCxERkSNgALID7u6Al5e4zmEwIiKihmMAshOcCE1ERGQ+JgWgdevWYevWrfrbL774Inx8fNCnTx9cvHjRbJWjcpwITUREZD4mBaA33ngDbm5uAIC0tDQsXboUCxYsgJ+fH5577jmzVpAE9gARERGZj0lng7906RLatm0LANi8eTMeffRRTJ48GX379sWAAQPMWT/6C3uAiIiIzMekHiBPT0/cuHEDALBjxw4MGjQIAODq6oo7d+6Yr3akx6NBExERmY9JPUCDBg3CxIkT0b17d/z2228YNmwYAODkyZMIDQ01Z/3oLxwCIyIiMh+TeoCWLl2K6OhoXLt2DV999RWaNWsGADh8+DBGjx5t1gqSwCEwIiIi8zGpB8jHxwfvv/9+lfWzZ89ucIXIOPYAERERmY9JPUDbt2/HTz/9pL+9dOlSdOvWDY8//jj+/PNPs1WOylXsAeLpMIiIiBrGpAA0ffp05OfnAwCOHz+O559/HsOGDUNGRgYSEhLMWkESdAFIowGYMYmIiBrGpCGwjIwMdOrUCQDw1Vdf4YEHHsAbb7yBI0eO6CdEk3m5uABNm4rwk5MD+PrKXSMiIiL7ZVIPkLOzMwoLCwEAO3fuxODBgwEAvr6++p4hMj9OhCYiIjIPk3qA+vXrh4SEBPTt2xeHDh3Cxo0bAQC//fYbgoODzVpBKhcQAJw5w4nQREREDWVSD9D7778PJycnfPnll1i+fDlatmwJAPj+++8xZMgQs1aQyrEHiIiIyDxM6gFq1aoVvvvuuyrr33nnnQZXiKrHo0ETERGZh0kBCADKysqwefNmnD59GgDQuXNnPPTQQ1CpVGarHBnisYCIiIjMw6QAdO7cOQwbNgyXL19G+/btAQDz5s1DSEgItm7divDwcLNWkgQOgREREZmHSXOAnnnmGYSHh+PSpUs4cuQIjhw5gszMTISFheGZZ54xdx3pL+wBIiIiMg+TeoD27NmDAwcOwLfCwWiaNWuG+fPno2/fvmarHBliDxAREZF5mNQD5OLiglu3blVZf/v2bTg7Oze4UmScrgcoNxfQauWtCxERkT0zKQA98MADmDx5Mg4ePAhJkiBJEg4cOIB///vfeOihh8xdR/pL8+aAQgGUlQE3bshdGyIiIvtlUgBasmQJwsPDER0dDVdXV7i6uqJPnz5o27YtFi9ebOYqko5aDTRrJq5zGIyIiMh0Js0B8vHxwZYtW3Du3Dn9bvAdO3ZE27ZtzVo5qiogALh+XUyEjoyUuzZERET2qc4BqLazvO/evVt/fdGiRabXiGoUEACcOMEeICIiooaocwA6evRonbZTKBQmV4Zqxz3BiIiIGq7OAahiDw/Jh8cCIiIiajiTJkGTfNgDRERE1HAMQHaGJ0QlIiJqOAYgO8MhMCIiooZjALIzHAIjIiJqOAYgO6PrAbp+HSgtlbcuRERE9ooByM40awYolYAkAdeuyV0bIiIi+yR7AFq6dClCQ0Ph6uqKqKgoHDp0qNptT548iUcffRShoaFQKBRGT7sxa9YsKBQKg6VDhw4WbIF1qVRAixbiOofBiIiITCNrANq4cSMSEhKQlJSEI0eOoGvXroiNjUVubq7R7QsLC9GmTRvMnz8fAbqxICM6d+6Mq1ev6peffvrJUk2QBSdCExERNYysAWjRokWYNGkSxo8fj06dOmHFihVwd3fH6tWrjW5/11134a233sKoUaPg4uJSbblOTk4ICAjQL35+fpZqgiw4EZqIiKhhTDoZqjmUlJTg8OHDmDFjhn6dUqlETEwM0tLSGlR2eno6goKC4OrqiujoaMybNw+tWrWqdvvi4mIUFxfrb+fn5wMANBoNNBpNg+pSma68hpTbooUKgBJXrpRBo9GaqWbmYY722TJHbx/g+G1k++yfo7eR7Wt42XUhWwC6fv06ysrK4K/rzviLv78/zpw5Y3K5UVFRWLt2Ldq3b4+rV69i9uzZuPvuu3HixAl4eXkZfcy8efMwe/bsKut37NgBd3d3k+tSk+TkZJMfe/t2JwAROHDgArZtO2G+SplRQ9pnDxy9fYDjt5Hts3+O3ka2r/4KCwvrvK1sAchShg4dqr/epUsXREVFoXXr1vj8888xYcIEo4+ZMWOGwdnu8/PzERISgsGDB8Pb29us9dNoNEhOTsagQYOgVqtNKiM9XYlNmwA3tzAMG1Z9z5YczNE+W+bo7QMcv41sn/1z9DayfabTjeDUhWwByM/PDyqVCjmVZvLm5OTUOMG5vnx8fNCuXTucO3eu2m1cXFyMzilSq9UW+/A1pOyWLcXltWtKqNWy78hnlCVfO1vg6O0DHL+NbJ/9c/Q2sn2mlVlXsv16Ojs7o2fPnkhJSdGv02q1SElJQXR0tNme5/bt2zh//jwCAwPNVqbcOAmaiIioYWQdAktISMDYsWPRq1cv9O7dG4sXL0ZBQQHGjx8PAHjiiSfQsmVLzJs3D4CYOH3q1Cn99cuXL+PYsWPw9PRE27ZtAQAvvPACHnzwQbRu3RpXrlxBUlISVCoVRo8eLU8jLYC7wRMRETWMrAFo5MiRuHbtGhITE5GdnY1u3bph+/bt+onRmZmZUCrLO6muXLmC7t27628vXLgQCxcuRP/+/ZGamgoAyMrKwujRo3Hjxg00b94c/fr1w4EDB9C8eXOrts2SdD1Af/wBFBcDNRwRgIiIiIyQfRJ0fHw84uPjjd6nCzU6oaGhkCSpxvI2bNhgrqrZrKZNAbUa0GiA3FwgJETuGhEREdkX25xBSzVSKst7gTgMRkREVH8MQHaKE6GJiIhMxwBkpzgRmoiIyHQMQHaKPUBERESmYwCyU7oeIAYgIiKi+mMAslMcAiMiIjIdA5Cd4hAYERGR6RiA7BR7gIiIiEzHAGSn2ANERERkOgYgO6XrAcrPB+7ckbcuRERE9oYByE55ewOuruI6h8GIiIjqhwHITikUHAYjIiIyFQOQHeNEaCIiItMwANkx9gARERGZhgHIjvFo0ERERKZhALJjHAIjIiIyDQOQHeMQGBERkWkYgOwYe4CIiIhMwwBkx9gDREREZBoGIDvGSdBERESmYQCyY7oeoMJC4PZteetCRERkTxiA7JinJ+DhIa6zF4iIiKjuGIDsHCdCExER1R8DkJ3jRGgiIqL6YwCyc5wITUREVH8MQHaOQ2BERET1xwBk5zgERkREVH8MQHaOPUBERET1xwBk5zgHiIiIqP4YgOwch8CIiIjqjwHIzlUcApMkeetCRERkLxiA7JyuB6i4GLh5U966EBER2QsGIDvn6go0aSKucyI0ERFR3TAAOQBOhCYiIqofBiAHwInQRERE9cMA5AB4LCAiIqL6YQByAOwBIiIiqh8GIAfAHiAiIqL6YQByAJwETUREVD8MQA6AQ2BERET1wwDkAHQ9QJmZQFaWvHUhIiKyBwxADmD3bnF5/TrQujXw0Ufy1oeIiMjWyR6Ali5ditDQULi6uiIqKgqHDh2qdtuTJ0/i0UcfRWhoKBQKBRYvXtzgMu1dVhbw0kvlt7VaYMoU9gQRERHVRNYAtHHjRiQkJCApKQlHjhxB165dERsbi9zcXKPbFxYWok2bNpg/fz4CdOM+DSzT3qWni9BTUVkZcO6cPPUhIiKyB05yPvmiRYswadIkjB8/HgCwYsUKbN26FatXr8bLL79cZfu77roLd911FwAYvd+UMgGguLgYxcXF+tv5+fkAAI1GA41GY3oDjdCVZ65yQ0MBpdIJWq1Cv06plNC6dSnMXPU6MXf7bI2jtw9w/DayffbP0dvI9jW87LpQSJIkmb0GdVBSUgJ3d3d8+eWXiIuL068fO3Ys8vLysGXLlhofHxoaimnTpmHatGkNLnPWrFmYPXt2lfWffvop3N3d69UuOSQnt8Ly5V2h1YoOPaVSi9df34eOHf+QuWZERETWU1hYiMcffxw3b96Et7d3jdvK1gN0/fp1lJWVwV+3D/df/P39cebMGauWOWPGDCQkJOhv5+fnIyQkBIMHD671BawvjUaD5ORkDBo0CGq12ixlDhsGPP98GdLTtXjnHSW2b1di0aJ+2LevFKGhZnmKOrNE+2yJo7cPcPw2sn32z9HbyPaZTjeCUxeyDoHZChcXF7i4uFRZr1arLfbhM3fZYWFi6dsXuOce4MgRBR55RI39+wEvL7M9TZ1Z8rWzBY7ePsDx28j22T9HbyPbZ1qZdSXbJGg/Pz+oVCrkVDp/Q05OTrUTnOUo0954eABbtgCBgcCJE8Do0WJSNBEREZWTLQA5OzujZ8+eSElJ0a/TarVISUlBdHS0zZRpj4KDRQhydQW2bjXcTZ6IiIhk3g0+ISEBq1atwrp163D69Gk89dRTKCgo0O/B9cQTT2DGjBn67UtKSnDs2DEcO3YMJSUluHz5Mo4dO4ZzFfb5rq3MxuKuu4B168T1t9/mwRGJiIgqknUO0MiRI3Ht2jUkJiYiOzsb3bp1w/bt2/WTmDMzM6FUlme0K1euoHv37vrbCxcuxMKFC9G/f3+kpqbWqczGZMQI4MwZICkJeOopoG1boH9/uWtFREQkP9knQcfHxyM+Pt7ofbpQoxMaGoq67LVfU5mNzcyZwOnTwIYNwCOPAIcOAeHhcteKiIhIXrKfCoMsS6EAVq8WQ2J//AE88ABw86bctSIiIpIXA1Aj4OYmJkUHB4shsZEjgdJSuWtFREQkHwagRiIwEPjmG8DdHfjhB+D55+WuERERkXwYgBqR7t2Bjz8W15csAVaskLc+REREcmEAamQefhh44w1xPT4e2LlT3voQERHJgQGoEXr5ZeBf/xJHiP7HP4DffpO7RkRERNbFANQIKRTAqlVAnz5AXp7YM+zPP+WuFRERkfUwADVSLi7Apk1Aq1ZAejrw2GOARiN3rYiIiKyDAagRa9EC+PZbwNMT2LUL+L//A+pwnEkiIiK7xwDUyHXpAnz6qRgWW7kSeP99uWtERERkeQxAhAcfBN56S1yfNg3Yvl3W6hAREVkcA5C1ZWXB7/hxICtL7poYSEgAnnwS0GrFkaJPn5a7RkRERJbDAGRNH30Ep7Zt0XfmTDi1bQt89JHcNdJTKIDly4F77gHy88WeYdevy10rIiIiy2AAspasLGDSJCi0WgAQl1Om2FRPkLMz8NVXQFgY8PvvwKOPAiUlcteKiIjI/BiArCU9veouVmVlwLlz8tSnGn5+wHffAd7ewN69wFNPAZcuAbt321RWIyIiahAGIGuJiACUlV5uhQJo21ae+tSgUydg40ZR3dWrgdatgYEDxaUNjdoRERGZjAHIWoKDgQ8+gKRSla+TJOCLL+SrUw2GDAGSksR1XceVDY7aERERmYQByJomTEBpejp+mjMHZfHxYl1CAvDOO/LWqxr9+lVdZ4OjdkRERPXGAGRtwcG4ERkJ7dtvAzNninU2GoLatas6ageII0cTERHZMwYguSgUwOzZNh2C/hq1Q8VROwC4/35x6gwiIiJ7xQAkJzsIQRMmABcuiL3A9uwRp87IzQUGDQLmzhXzgoiIiOwNA5Dc7CAEBQcDAwaIgyQeOFB+xOiZM0VvEA+YSERE9oYByBbYQQjScXMTu8KvWSOub98OdO8OpKXJXTMiIqK6YwCyFXYUggBg3Djg4EExUTorS/QOvfNO1WM9EhER2SIGIFtiLAQtWiRvnWoQGQn873/AiBFAaamo7siRKhQUOMldNSIiohoxANkaXQhKTBS3n3/epkOQtzewYQPw3nuAWg1s3qzE88/3x7FjcteMiIioegxAtkihAGbNspsQpFAA8fHATz8BrVpJyM72xN13O2HVKg6JERGRbWIAslV2FoIAoHdv4NChUvTqlY3iYgUmTwbGjgUKCuSuGRERkSEGIFtmhyHI1xd45ZWDmDu3DEol8N//AlFRwJkzcteMiIioHAOQrbPDEKRUAi++qMWuXUBAAHDyJNCrF/DZZ3LXjIiISGAAsgd2GIIAoH9/4OhR4N57xTDY448DU6cCxcVy14yIiBo7BiB7YachKCAASE4G/vMfcXv5cqBvXyAjQ956ERFR48YAZE/sNASpVOK8Ydu2iTlChw8DPXoAq1eLc4xlZcldQyIiamwYgOyNnYYgABg6VAyJRUUBeXniRKsDBwKtW4vTaxAREVkLA5A9MhaCEhPtojulVSvg009FE3S0WmDiRGDyZCA1FdBoZKseERE1EgxA9qpyCJozx266Uy5eNH6AxFWrxITpFi2A0aNFUPrzT+vXj4iIHB8DkD1TKETXSeXulEmTgLVrgZIS2apWk4gIsat8RUol8OijgJ+fGB7bsAEYMwZo3hwYMABYuBA4e1aO2hIRkSNiALJ3585V7U6RJGD8eMDfX0y0SU4WZyu1EcHBwAcfiMnRgLj84APgyy+B7Gxg3z7g5ZeBzp2BsjJgzx5g+nSgQwdx9vnnnxejfRwqIyIiUzEA2Ttj3SkKhRhHyssTu1oNHgwEBYmD8OzdK3qJZDZhAnDhgggyFy6I24AIQ336APPmASdOAL//DixZAgwaJE62mp4u5nwPHFjzUFlWll1MiSIiIpkwANk7Y90pq1YBV66IGcX//rcYV7p2TRyEp39/MRM5IQE4dEjWs5UGB4vhreDg6rcJCwP+7/+AHTuA69dFL9HYscaHyvr3F0Nlr78upkLZyZQoIiKSAQOQIzDWnaJSiUSwfLkIQ9u3i2GxJk2Ay5eBd94R+6OHhwMzZgC//GLzp2739hbzhNauLR8qmzED+NvfxFDZ3r1iqOzVV8s7ubRaYMoU9gQREZEhBiBHUVN3iloNxMaK4bCcHGDLFjF25OEhDsk8fz7QrRvQsaPYs6zymUttcDxJN1T2xhvA8ePlQ2W9elXdtqwMOHbM6lUkIiIbZhMBaOnSpQgNDYWrqyuioqJw6NChGrf/4osv0KFDB7i6uiIyMhLbtm0zuH/cuHFQKBQGy5AhQyzZBPvh4gI89JCYOJObC3z+OfDII2L92bPA7NkiCHXrJibizJ9vF+NJuqGyTZuqTokCRN5LTAT++MP6dSMiItsjewDauHEjEhISkJSUhCNHjqBr166IjY1Fbm6u0e3379+P0aNHY8KECTh69Cji4uIQFxeHEydOGGw3ZMgQXL16Vb98xlORV+XuDvzjH8BXX4kwtH49cP/9gJOTGBJ75RUxxmRH40mVp0QplWL+9+3b4lBJoaHivGTXr8taTSIikpmT3BVYtGgRJk2ahPHjxwMAVqxYga1bt2L16tV4+eWXq2z/7rvvYsiQIZg+fToAYM6cOUhOTsb777+PFStW6LdzcXFBQEBAnepQXFyM4gqnKM/PzwcAaDQaaMy8r7WuPHOX22BubsCoUWK5cQOKLVugXLkSyqNHDbcrK0PZc89BeuopSNHRIixVYAvte+IJ0WF1/rwC4eESgoKAzZsVeP11FY4fV+CNN4B335Xw1FNaPPecFs2b171sW2ifpTl6G9k+++fobWT7Gl52XSgkSb6ZryUlJXB3d8eXX36JuLg4/fqxY8ciLy8PW7ZsqfKYVq1aISEhAdOmTdOvS0pKwubNm/HLL78AEENgmzdvhrOzM5o2bYqBAwdi7ty5aNasmdF6zJo1C7Nnz66y/tNPP4W7u3vDGmnHXK9fx+BJk6Co5iNS4uWFnJ49cbV3b1zr3h2lbm5WrmH9aLXAoUMB+Pzz9vj9dx8AgItLKYYOzUBc3Hn4+BTXXAARUSPiev06PK9exe3AQBT5+cldnTopLCzE448/jps3b8Lb27vGbWXtAbp+/TrKysrg7+9vsN7f3x9nKk/E/Ut2drbR7bOzs/W3hwwZgkceeQRhYWE4f/48XnnlFQwdOhRpaWlQ6cZGKpgxYwYSEhL0t/Pz8xESEoLBgwfX+gLWl0ajQXJyMgYNGgS1Wm3Wsi2hrKwMqqlToSgrg6RSQTthAhQFBVB8/z2c//gDIampCElNheTsDGnAAJQOHYrdnp64+/HHbbJ9Dzwgpjlt21aKuXOVOHzYCZs3R+CHH9pi0iQtnn9ei8DA6h9vb+8fACArC4pz5yC1bVvzMQf+YpdtrAe2z/45ehttoX2KVaugio+HQpIgKZUoW74c0l8jNQ1lyfbpRnDqQvYhMEsYNWqU/npkZCS6dOmC8PBwpKam4r777quyvYuLC1xcXKqsV6vVFvvwWbJss5o8GRg2DDh3Doq2baHS/YCWlgL79wPffANs2QLFuXNQ7NgB5x07EAtAWroUiuHDxYTr7t0NT9dhA+LigOHDxdEBZs8GDh5UYMkSFVauVGHyZOCll4CWLat/vN28f6tWiWNBabViQtQHH5QfdbIWdtNGE7F99s+u2piVJY7kGhFRp39EAJna98svYpfa1av1qxRaLZymTBGHWRk5EujSxSzf6ZZoX33Kk3UStJ+fH1QqFXJycgzW5+TkVDt/JyAgoF7bA0CbNm3g5+eHc+fONbzSjZGxXeydnIB77hFHHvztN+D0aeDNN6Ht0weSQgHFsWMiWfTsKQ68OHWqSBsV5lpZdPf6OpStUABDhwJpacAPP4jd6ouLgffeA9q0AZ5+Grh0yfxVMzutVlQ0JQVYsUKcK+Shh4C2bUWArTiJfeJEcbCk/ft5LhEia1m1yrb3pr1xQ3zx9egh9gCuEH4MzJsn7m/ZEhg3DvjsM7veo0TWHiBnZ2f07NkTKSkp+jlAWq0WKSkpiI+PN/qY6OhopKSkGMwBSk5ORnR0dLXPk5WVhRs3biCwprENMp1CIU7U1aEDyp57Djs/+wyDNBo4bd0qkkVWljgg4/LlgKenOCZRkybiiIa19UxIkvihLi4WJ3etuFRep7u9bZt4LkkSZS9dKnpBaqj+4MHidBu7donc9uOPwLJl4nvrySfFznCtW4umHD/uhy5dxK73ZlXTf4iSBFy9Ku6vvJw7BxQV1f15Fi4Ui4cH0K8fcO+9YunRo8qkdiIy0e+/Azt3il7yrVvL1+tOWO3lJbqinZ3lqV9pqTjE/po1oo66k2er1eLL8PvvDQ+Oq1CI74kDB8R30bp1YlEoxAHYYmPF8ve/28/3iCSzDRs2SC4uLtLatWulU6dOSZMnT5Z8fHyk7OxsSZIk6V//+pf08ssv67fft2+f5OTkJC1cuFA6ffq0lJSUJKnVaun48eOSJEnSrVu3pBdeeEFKS0uTMjIypJ07d0o9evSQIiIipKKiojrV6ebNmxIA6ebNm2Zvb0lJibR582appKTE7GXbgirtu3NHkrZulaQpUyQpMFCSxJ+U8SUoSJICAiSpaVNJ8vCQJLW65u3rs7RoIUnR0ZI0apQkvfSSJC1bJknbtknSyZOSdPt2lXbs3i1J995b/nAnJ0m6+25JUiq1EiAuP/zQjC/chx9KklIp/VW4JI0bJ0kzZkjSY49JUteu4vWoqX1OTpLUrp0k3X+/JE2bJklLl0rSJ5+Ul6lblEqxjZ9f1TK8vSXpgQek0gULpN2LFkkldfx7sTeN7m/QAdlkG69dk6SNGyVp0iRJCgur2/eSp6ckPfSQJC1fLkkZGfqiLNq+06cl6cUXq34fd+8uSUuWSNL162K7Dz+UJJVK3KdSSfovvKIiSdq5U5KmT5ekLl2qtqlJE0l65BFJWrlSki5cMFoFS7avPr/fsse0kSNH4tq1a0hMTER2dja6deuG7du36yc6Z2ZmQlnhyHZ9+vTBp59+ildffRWvvPIKIiIisHnzZvztb38DAKhUKvz6669Yt24d8vLyEBQUhMGDB2POnDlG5/mQhbm6ijlEw4aJLpUjR8T48n//W3XbK1dqL0+hEAdtdHER/zlVXFxcRE/Ib79VfVxurljS0oyX6+cnunj+WgaEhmLAs63x4z874bX1odi5R40ffwQAMe6t1SoweZKETp0UiIr66+CLkgTcuSNOUnbzprisuFS37to14Pz58rpotaJ3rDKVShzIKCKi6tK6tfH/uu7cEcduKisTj1+5UvS0abXAyZNimHDXLmDPHlGf776D6rvvMACANHeuOJ2Kroeoc2ebm8tFJJvCQuCnn0Qvz86dQOVDhjg5AdHRwF13AYsXG56EWqEAfH3F0NM334gFANq3B4YOhSImBkpdj4w53LwJbNwoensOHChf7+cnTqY4fjzQtavhYyZMED06586J4XRdr7SLC3DffWJZsEB8b+/YIXr7k5NFm77+WiyAGB3Q9Q717y+OP5eVBb/jx2GZrvS6k3U3eFuVn5+PJk2a1Gk3uvrSaDTYtm0bhg0bZj+T9+qhTu3LyhI/2BW/EJRK8SUQElI11FS8bWQvvlrLVqmAzZtFOLp4USwXLpRf1mGvgfecE/BMydtG73NVFCFC+Tvaa0+jvXQa7XFWvzRB3fdIqOKhh8Tcq3btRMgJDTWtuzwrq+qXWGVlZWLy4+7d0O7ahbLdu6G+c8dwmxYtRH10gahdO3FeuXpO7JSbXf4N1mMCbb3bZ8LkXLlpMjJw6JNP0HvMGKit9QNaVgYcPlweePbtKx820omMBGJixHLPPWLIHxBzfir/IzJ+vPib+/57MT9y/35x/19KnZ2hHDgQyqFDxWTFtm3r9w+IViv+wVmzRoQR3d+zSiXKGz9e7BZrziG4sjLxT+727SIQHThg0Ca4uADh4ZBOn9bvXaaox44ZdVGf328GICMYgExX5/YZ+0Iw1x9BfcvOyysPRhXDke769evIQku0xkVoUTGASXCCBqWo/gvE3+k62nlcQXufHLRv/gfaB91C+1Z3EBYGqJt5Az4+4kt01ChkaQORjghEIB3Bqmzx3DL8IGk0Gnz/7bcY5u8Ppx9/FF+iP/5Y/gWq06SJ+M8SEF/ML70kXvegIPnmNdSB3f0NrlwpdiLQzZf7z39EONYNOmi1BpelJSU4kJaGv0dFwUmpNNym8vY//CDmyOnmyyUlicmtXl5iachcDksFq48+gjR5MhRarfl/QCvWuWVLcV0XeHbvFt8VFQUHi/kyMTFignNNB9+t7R+RmzfF82zfDun776G4fNnw/jZtgCFDRHi5914xh69ynYODxfkd164V83MuXix/fMeOIvT8618119Oc8vJED/MPP4hQlJlZdRuVyqzfdQxADcQAZLp6ta8uPROmMmfZBQXAoUP4aOAnmIIVKIMTVCjFSsVTGLuqHy56dsbZG344m9MEZ7M8cPZ3Nc6eVeDq1eqLdHICwsNFj3f79kDuvt/w3/3h0EIFJcrwwdj9mLD27obV20RG38OSEuDQofIhs/37q/73W1Hz5uIHpGVL8frrrldcfHyq/4/Wgr0SFv0brG+9CwpEL1pWllh013WXFy/Ku5eNi0t5GKq4eHrWvO6nn8qHfZRK4MUXxY93SYnYqUGjMe36n38CGzZUnZz7r3+Jz5OTk5jEW/GyuuuV1+3aJfaEkiRRpo+PeL6KmjQRQUfXyxMRYZFhYU1JCX5csQL979yBascO8Q9Ixb02nZ1FD1PTpuJURlqtqEe7duKcjhXrO3q0CLW9e8s7hC1J4nRL48ZVvW/3btG7bAYMQA3EAGQ6h27fRx/h0uTXcF4bhnBlBkI+SKzxP8/8fDEd6exZseiu//abmD5QE4VC/BMXFweY+SNYqzq9hz/8IH7QKlOr6757vbu78WB05ozo9dD9eL7/vuhZMnaWWxNYbPjko4/KDzugVALvvCO+1I0FG931yj0KddW8uTh9jVIpPiwKhf66BOD2nTvw9PSEQqWqcr/++q1bxufLOTmJPYRIfJ779SsPPFbaU7LK3+Dt2yIkfP+9WC5cqLmAQYNEb09cnPic2IrqpijI1AMk+yRoIrsxYQICBg7ExU8+QcCYMbVO3vP2FnuH9upluF6rFb99umCUkiLOYl+RJAFjx4rfqZ49xe/ogAHiu9jagciozp1F5Sp/kZ0/L75wL1+uuuh+9C9fBv74Q6RA3a781dFqxfDP1Knix8jNTUysd3Utv25sXXXXjx6F02efoa8kQUpMBB5/XPxnXFoqFo3G+PWa7tNoxA9UaqphvZ99tm6vpaen+PLXLbpes+Bg8WN7//1VX+cjR6r9wSjVaLCrLv+EVPdjlJEh5nvdulW+3L5teLum9ZcvA6dOVX2+kBDRq+LsLN5Ltdr49ZruLywE3n67ag/QtGniPa78/tT0nlW8vHHDeJ2/+cZ40Lc2T0/gwQfFIkkiuL73nhi+rGzDBnGwQlv019mqpSlT9GcXUKxcKdvcMwYgovoIDsaNyMgG/cEqleK3ICRE/FM5fDiwZUvVnURatRIjIP/7n1jeesuGAtFfX2RV5lqFhIj7/fyq7lVS0Z07Yu+RysHo6FFg717jj9ENhdTjUPfG6AYBFJIEfPKJWCzF21vM3agYaipfr+0NNPY6m+MHo7r3UFd2s2Ziqa/qgtX+/eapd4cOVX9AGzoHqLo6/7V3sU1RKMS4+csvi+OdVa5z377y1a0uJkxA6cCBOPjJJ4iy5iR2IxiAiGRW3e/QhAniAM979ojOhdRU0cFiM4Gout1k68LNTUyCCg83XF/dD9GRI2K34aIiEZ6Kiup2veK6jAyxm25l994rgohuPkhd5o9Uvp2fL47AXbFnQqUShxpo6I9+Q15nOcquLVg1lCV+QC1dZ0uwxzrrmOEfSXNgACKyAdX9DoWEAP/8p1gA0wJRfr4F93LW9WSYszxjX+pdujS87OrC1fr15mmDt7flfozM/TpbumxLhjbAMj+glq6zJdhjnW0IAxCRjajL71B9A5FCUd4poVAAiYnitB42fUxQS32pW3r+AX+MDFkytFkK69yoMAAR2bGaAtHOnYaHAZEkcZ6zOXPEwVkjI8UUh8hIsYSGmm1Hq4az1Je6pecf8MeIyG4wABE5kIqBaPducciSyrRascPLqVPi6Pg6Hh4iEHXqpIJS2QZubgp07y72uK6OHR5E2GbmHxCRvBiAiBxURITxPdXT0sSx9Y4fB06cEJenTolj8h08CBw8qAQQiY8+Eo/x96/aW9S5M/DZZ4aHvbHUAXmZU4jIEhiAiBxUdfOJ77pL3D90aPm2paUicBw/Dhw7VoZdu3Jx/XoAfv9dgZwcICdHDKlVR6sFJk0S018CAsROXrpFdxiemtZVPFxN5eMJmvlUQUREABiAiBxaXeflOjmJUwV17Ag8/LAWUVGHMGzYMJSUqHHypGFv0fHjQG5u1TIkCZg/37R6qlQiFDk7G559QBes0tNFD1RIiDg+UsuWNn26MSKyAwxARA6uIfNyPTzEgZJ79zZcf+yY2N2+8sEbH3tM9NroDsFTeam4vqio/LFlZWIIrqCgah0kCXjzTcN1CoXoadIdULJVq6rX/f2NT+rOygKOH/dDly61HsybiBwYAxAR1Vu3btUfvLGutFqguNgwEGVkiB6rysHqkUfE2TMuXRJLcTFw9apYDh0yXr5aLYJfxVCUmQl8+qkTJKkvkpIkDq8RNWIMQERkkoYe9kapLJ8DpBMeXnuwkiTg2jURhDIzy0NRxetXroizZmRkiMWQOBmGVqvAxInAqlViUnd4uGhH27biepMmJr0sRGQnGICIyGRyHERYoRDn6mzRQgzDGVNaKkJQxWCUlgZs3lx1W7HnW9X1fn5VQ5Huup+fqEdl3HuNyH4wABGRzWlosHJyEsNerVqVnxsyK0uc3Lvi8JpSCSxeLCZenz8vQtf582Kvt+vXxWIsHHl5VQ1FZ84AixZx7zUie8EARESNQvlhASSUlSmgUklYuVJhNKTcuiWCUMVQdO6cWLKyxP1Hj4rFGN3eawUFwKBBQLt2YjjPFrHXihorBiAiajQmTAAGDizFJ58cxJgxUQgLUxvdzstLTPTu1q3qfbrJ2hXD0cGD4vxrFUkS8Oyz4rq7uzifa/fuQI8e4vJvf5PnnGwlJWJI8MIF4OOPgXXrRF0VCuCpp4CRI4FmzQBfX7GYWkcGK7J1DEBE1KgEBwORkTdM/lF2dS0/ZpKOsRPNKxQi7Jw5I3qCDhwQi46TE9CpU3kg6t5dBC4vr6rPWZ8wUVgIZGV54ocfFLh8WZwP7sKF8surV8tPkFuRJAHLlomlIg+P8kBk7NLYuk2bRJjicCDZMgYgIqIGqu6o2xMmiNvp6eVDZkePAkeOiN36f/1VLGvXlpcVEVEeiLp3F6cpeeGF8jDx7rtA//5Vg83Fi2LJzVUDuK/G+rq5iYncly4Zb0tRkaifVlt+fKbMTNNeG91woL8/MHgwD2BJtoMBiIjIDKrbe02lAjp0EMvo0WKdJInwoQtDumCk6+lJTwc+/7zqc2i1wP/9X+11cXPTIDzcCWFhCrRuLXqnQkPLL/38gMuXq/Za6c4VFxws1ufnAzduiOWPPwwvq1t382bV+kgS8OCDIvx07y4OrBkVJS7btjW+Rx2RpTEAERGZSV33XlMoyvdSGz68fP21a4Y9RT/9JIJKZV5eoqeocrBp3RoICtJg//5tuP/+YVCrjc9x0tXVWK+Vrv5KJeDjI5bw8Lq/BhcuiO0rBitAlJOXV37YgffeE+ubNjUMRL17A82b1/35iEzFAEREZCOaNxfDRIMHi9vG5hapVGJYrLqgpdHUvUeloQezNCY01HiwevJJ4PffRfg5dEhcHj0qDkHwww9i0QkLMwxFPXoYHjDTUqczsceJ2/ZYZ1vBAEREZKNq66Ux13NY62CW4eFiefxxcbukRMyB0gWiQ4fEpHHdEbw3bhTbOTkBkZEiEBUVAevXO0GrFaczefNNseeaVmt8kaTq76t4/zffAAsXls+1WrIEePpp874u5vbhh+Kzoavz8uXA5MnmK99S4cpWzsfHAEREZMMs0UtjDXUJVs7OQK9eYpk6VazLywN+/tmwpygnp/Jxl8pPZzJ9OjB9unnrrtUC8fGi3KAgceLdiktgoOHtFi3EuedqUtcwodWKA3BmZnohNVWBGzdE+3VLbq64vHxZHO284uOmTBGHXmjSRCze3mKpeL3ybWPXvbzE4REmT666J58kiXPxVV6Kiuq2bu9e4Msvxfn4EhMlrFol3x6CDEBERDbOEr00tsrHB4iJEQtQPmH80CHgiy+MTw5Xq0UvkUIhfqzrslTctqjI+FyrO3fKD4hZE4VCTCyvHJR0YenIkfKjhCsUYjiwQwfjwebaNaC0VA1goEmvX1GRWHJyTHq4UVotMHGiOLSBRmOOEkWAlSQFpkwRAV+OzzcDEBER2ayKE8b//nfgyy+rzon6/feG/YBWN9cqNVVcz842XK5eLb+ekyOGJ69dE8vx4zU/lyQBH31Ue508PUvQsqUaAQEK+PuLXiZ///JFoQDi4qrWee9eceymmzfFXny6peLt6q7n54vwVB1j4cfZWRwsU7e4uhrerrju5k1gzx7Dx5eVid5NBiAiIqJqVHc6k4b+eFY316pfv9ofqxuyqi4gnT4N/PJL1cfdd584OnjFUKMLOk2barBz5/cYNqzmPfmM1blPnwa8EBDDVGfPisMVVD5vXlqamOSuCzbOzmJ9XVUXNNu2bVidTcUAREREdqOupzMxpVxT5loplSK0tGghAk1l1f3or11b8558lqxzTVxcRDuMhavevRtWtqUCrKkYgIiIyK409HQmNZVriTItuSefpeaHWWryvaUCrCkYgIiIiCzIkffkM7VcSwTY+mIAIiIisrDGtCefvajH9CUiIiIix8AARERERI0OAxARERE1OgxARERE1OgwABEREVGjwwBEREREjQ4DEBERETU6DEBERETU6NhEAFq6dClCQ0Ph6uqKqKgoHDp0qMbtv/jiC3To0AGurq6IjIzEtm3bDO6XJAmJiYkIDAyEm5sbYmJikJ6ebskmEBERkR2RPQBt3LgRCQkJSEpKwpEjR9C1a1fExsYiNzfX6Pb79+/H6NGjMWHCBBw9ehRxcXGIi4vDiRMn9NssWLAAS5YswYoVK3Dw4EF4eHggNjYWRUVF1moWERER2TDZT4WxaNEiTJo0CePHjwcArFixAlu3bsXq1avx8ssvV9n+3XffxZAhQzB9+nQAwJw5c5CcnIz3338fK1asgCRJWLx4MV599VUMHz4cALB+/Xr4+/tj8+bNGDVqVJUyi4uLUVxcrL+dn58PANBoNNDU9bS8daQrz9zl2gq2z/45ehvZPvvn6G1k+xpedl0oJEmSzF6DOiopKYG7uzu+/PJLxMXF6dePHTsWeXl52LJlS5XHtGrVCgkJCZg2bZp+XVJSEjZv3oxffvkFv//+O8LDw3H06FF069ZNv03//v3RrVs3vPvuu1XKnDVrFmbPnl1l/Ycffgh3d/cGtZGIiIiso7CwEBMnTkReXh6aNGlS47ay9gBdv34dZWVl8Pf3N1jv7++PM2fOGH1Mdna20e2zs7P19+vWVbdNZTNmzEBCQoL+9uXLl9GpUydMnDixfg0iIiIi2d26dcu2A5CtcHFxgYuLi/62p6cnLl26BC8vLygUCrM+V35+PkJCQnDp0iV4e3ubtWxbwPbZP0dvI9tn/xy9jWyf6SRJwq1btxAUFFTrtrIGID8/P6hUKuTk5Bisz8nJQUBAgNHHBAQE1Li97jInJweBgYEG21QcEquJUqlEcHBwXZthEm9vb4f8YOuwffbP0dvI9tk/R28j22ea2np+dGTdC8zZ2Rk9e/ZESkqKfp1Wq0VKSgqio6ONPiY6OtpgewBITk7Wbx8WFoaAgACDbfLz83Hw4MFqyyQiIqLGRfYhsISEBIwdOxa9evVC7969sXjxYhQUFOj3CnviiSfQsmVLzJs3DwDw7LPPon///nj77bdx//33Y8OGDfj555/xwQcfAAAUCgWmTZuGuXPnIiIiAmFhYZg5cyaCgoIMJloTERFR4yV7ABo5ciSuXbuGxMREZGdno1u3bti+fbt+EnNmZiaUyvKOqj59+uDTTz/Fq6++ildeeQURERHYvHkz/va3v+m3efHFF1FQUIDJkycjLy8P/fr1w/bt2+Hq6mr19lXm4uKCpKQkgzlHjoTts3+O3ka2z/45ehvZPuuQdTd4IiIiIjnIfiRoIiIiImtjACIiIqJGhwGIiIiIGh0GICIiImp0GIAsYOnSpQgNDYWrqyuioqJw6NChGrf/4osv0KFDB7i6uiIyMhLbtm2zUk3rZ968ebjrrrvg5eWFFi1aIC4uDmfPnq3xMWvXroVCoTBYbGFvPGNmzZpVpa4dOnSo8TH28t7phIaGVmmjQqHA008/bXR7W3//9u7diwcffBBBQUFQKBTYvHmzwf2SJCExMRGBgYFwc3NDTEwM0tPTay23vn/DllRTGzUaDV566SVERkbCw8MDQUFBeOKJJ3DlypUayzTls24ptb2H48aNq1LXIUOG1FqurbyHtbXP2N+jQqHAW2+9VW2ZtvT+1eV3oaioCE8//TSaNWsGT09PPProo1UOaFyZqX+79cEAZGYbN25EQkICkpKScOTIEXTt2hWxsbHIzc01uv3+/fsxevRoTJgwAUePHkVcXBzi4uJw4sQJK9e8dnv27MHTTz+NAwcOIDk5GRqNBoMHD0ZBQUGNj/P29sbVq1f1y8WLF61U4/rr3LmzQV1/+umnare1p/dO53//+59B+5KTkwEA//jHP6p9jC2/fwUFBejatSuWLl1q9P4FCxZgyZIlWLFiBQ4ePAgPDw/ExsaiqKio2jLr+zdsaTW1sbCwEEeOHMHMmTNx5MgRfP311zh79iweeuihWsutz2fdkmp7DwFgyJAhBnX97LPPaizTlt7D2tpXsV1Xr17F6tWroVAo8Oijj9ZYrq28f3X5XXjuuefw7bff4osvvsCePXtw5coVPPLIIzWWa8rfbr1JZFa9e/eWnn76af3tsrIyKSgoSJo3b57R7UeMGCHdf//9BuuioqKkKVOmWLSe5pCbmysBkPbs2VPtNmvWrJGaNGlivUo1QFJSktS1a9c6b2/P753Os88+K4WHh0tardbo/fb0/gGQNm3apL+t1WqlgIAA6a233tKvy8vLk1xcXKTPPvus2nLq+zdsTZXbaMyhQ4ckANLFixer3aa+n3VrMda+sWPHSsOHD69XObb6Htbl/Rs+fLg0cODAGrex1fdPkqr+LuTl5UlqtVr64osv9NucPn1aAiClpaUZLcPUv936Yg+QGZWUlODw4cOIiYnRr1MqlYiJiUFaWprRx6SlpRlsDwCxsbHVbm9Lbt68CQDw9fWtcbvbt2+jdevWCAkJwfDhw3Hy5ElrVM8k6enpCAoKQps2bTBmzBhkZmZWu609v3eA+Lx+/PHHePLJJ2s86a89vX8VZWRkIDs72+A9atKkCaKioqp9j0z5G7Y1N2/ehEKhgI+PT43b1eezLrfU1FS0aNEC7du3x1NPPYUbN25Uu609v4c5OTnYunUrJkyYUOu2tvr+Vf5dOHz4MDQajcH70aFDB7Rq1ara98OUv11TMACZ0fXr11FWVqY/irWOv78/srOzjT4mOzu7XtvbCq1Wi2nTpqFv374GR+GurH379li9ejW2bNmCjz/+GFqtFn369EFWVpYVa1s3UVFRWLt2LbZv347ly5cjIyMDd999N27dumV0e3t973Q2b96MvLw8jBs3rtpt7On9q0z3PtTnPTLlb9iWFBUV4aWXXsLo0aNrPMlkfT/rchoyZAjWr1+PlJQUvPnmm9izZw+GDh2KsrIyo9vb83u4bt06eHl51To8ZKvvn7HfhezsbDg7O1cJ5LX9Luq2qetjTCH7qTDIPj399NM4ceJErePO0dHRBieh7dOnDzp27IiVK1dizpw5lq5mvQwdOlR/vUuXLoiKikLr1q3x+eef1+k/Mnvz0UcfYejQoQgKCqp2G3t6/xo7jUaDESNGQJIkLF++vMZt7emzPmrUKP31yMhIdOnSBeHh4UhNTcV9990nY83Mb/Xq1RgzZkytOxrY6vtX198FW8EeIDPy8/ODSqWqMrs9JycHAQEBRh8TEBBQr+1tQXx8PL777jvs3r0bwcHB9XqsWq1G9+7dce7cOQvVznx8fHzQrl27autqj++dzsWLF7Fz505MnDixXo+zp/dP9z7U5z0y5W/YFujCz8WLF5GcnFxj748xtX3WbUmbNm3g5+dXbV3t9T388ccfcfbs2Xr/TQK28f5V97sQEBCAkpIS5OXlGWxf2++ibpu6PsYUDEBm5OzsjJ49eyIlJUW/TqvVIiUlxeC/6Iqio6MNtgeA5OTkareXkyRJiI+Px6ZNm7Br1y6EhYXVu4yysjIcP34cgYGBFqihed2+fRvnz5+vtq729N5VtmbNGrRo0QL3339/vR5nT+9fWFgYAgICDN6j/Px8HDx4sNr3yJS/Ybnpwk96ejp27tyJZs2a1buM2j7rtiQrKws3btyotq72+B4Coke2Z8+e6Nq1a70fK+f7V9vvQs+ePaFWqw3ej7NnzyIzM7Pa98OUv11TK09mtGHDBsnFxUVau3atdOrUKWny5MmSj4+PlJ2dLUmSJP3rX/+SXn75Zf32+/btk5ycnKSFCxdKp0+flpKSkiS1Wi0dP35criZU66mnnpKaNGkipaamSlevXtUvhYWF+m0qt2/27NnSDz/8IJ0/f146fPiwNGrUKMnV1VU6efKkHE2o0fPPPy+lpqZKGRkZ0r59+6SYmBjJz89Pys3NlSTJvt+7isrKyqRWrVpJL730UpX77O39u3XrlnT06FHp6NGjEgBp0aJF0tGjR/V7QM2fP1/y8fGRtmzZIv3666/S8OHDpbCwMOnOnTv6MgYOHCi99957+tu1/Q1bW01tLCkpkR566CEpODhYOnbsmMHfZXFxsb6Mym2s7bNuK+27deuW9MILL0hpaWlSRkaGtHPnTqlHjx5SRESEVFRUVG37bOk9rO0zKkmSdPPmTcnd3V1avny50TJs+f2ry+/Cv//9b6lVq1bSrl27pJ9//lmKjo6WoqOjDcpp37699PXXX+tv1+Vvt6EYgCzgvffek1q1aiU5OztLvXv3lg4cOKC/r3///tLYsWMNtv/888+ldu3aSc7OzlLnzp2lrVu3WrnGdQPA6LJmzRr9NpXbN23aNP1r4e/vLw0bNkw6cuSI9StfByNHjpQCAwMlZ2dnqWXLltLIkSOlc+fO6e+35/euoh9++EECIJ09e7bKffb2/u3evdvoZ1LXBq1WK82cOVPy9/eXXFxcpPvuu69Ku1u3bi0lJSUZrKvpb9jaampjRkZGtX+Xu3fv1pdRuY21fdatqab2FRYWSoMHD5aaN28uqdVqqXXr1tKkSZOqBBlbfg9r+4xKkiStXLlScnNzk/Ly8oyWYcvvX11+F+7cuSNNnTpVatq0qeTu7i49/PDD0tWrV6uUU/ExdfnbbSjFX09MRERE1GhwDhARERE1OgxARERE1OgwABEREVGjwwBEREREjQ4DEBERETU6DEBERETU6DAAERERUaPDAERERESNDgMQEVEdpKamQqFQVDmpIxHZJwYgIiIianQYgIiIiKjRYQAiIrug1Woxb948hIWFwc3NDV27dsWXX34JoHx4auvWrejSpQtcXV3x97//HSdOnDAo46uvvkLnzp3h4uKC0NBQvP322wb3FxcX46WXXkJISAhcXFzQtm1bfPTRRwbbHD58GL169YK7uzv69OmDs2fPWrbhRGQRDEBEZBfmzZuH9evXY8WKFTh58iSee+45/POf/8SePXv020yfPh1vv/02/ve//6F58+Z48MEHodFoAIjgMmLECIwaNQrHjx/HrFmzMHPmTKxdu1b/+CeeeAKfffYZlixZgtOnT2PlypXw9PQ0qMd//vMfvP322/j555/h5OSEJ5980irtJyLz4tngicjmFRcXw9fXFzt37kR0dLR+/cSJE1FYWIjJkyfj3nvvxYYNGzBy5EgAwB9//IHg4GCsXbsWI0aMwJgxY3Dt2jXs2LFD//gXX3wRW7duxcmTJ/Hbb7+hffv2SE5ORkxMTJU6pKam4t5778XOnTtx3333AQC2bduG+++/H3fu3IGrq6uFXwUiMif2ABGRzTt37hwKCwsxaNAgeHp66pf169fj/Pnz+u0qhiNfX1+0b98ep0+fBgCcPn0affv2NSi3b9++SE9PR1lZGY4dOwaVSoX+/fvXWJcuXbrorwcGBgIAcnNzG9xGIrIuJ7krQERUm9u3bwMAtm7dipYtWxrc5+LiYhCCTOXm5lan7dRqtf66QqEAIOYnEZF9YQ8QEdm8Tp06wcXFBZmZmWjbtq3BEhISot/uwIED+ut//vknfvvtN3Ts2BEA0LFjR+zbt8+g3H379qFdu3ZQqVSIjIyEVqs1mFNERI6LPUBEZPO8vLzwwgsv4LnnnoNWq0W/fv1w8+ZN7Nu3D97e3mjdujUA4LXXXkOzZs3g7++P//znP/Dz80NcXBwA4Pnnn8ddd92FOXPmYOTIkUhLS8P777+PZcuWAQBCQ0MxduxYPPnkk1iyZAm6du2KixcvIjc3FyNGjJCr6URkIQxARGQX5syZg+bNm2PevHn4/fff4ePjgx49euCVV17RD0HNnz8fzz77LNLT09GtWzd8++23cHZ2BgD06NEDn3/+ORITEzFnzhwEBgbitddew7hx4/TPsXz5crzyyiuYOnUqbty4gVatWuGVV16Ro7lEZGHcC4yI7J5uD60///wTPj4+cleHiOwA5wARERFRo8MARERERI0Oh8CIiIio0WEPEBERETU6DEBERETU6DAAERERUaPDAERERESNDgMQERERNToMQERERNToMAARERFRo8MARERERI3O/wMyrpM55M5lzwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전이학습\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Input,layers,optimizers,models,metrics\n",
        "from tensorflow.keras.layers import Dense,Flatten,Activation,Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!git clone https://github.com/taehojo/data-ch20.git\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,horizontal_flip =True,width_shift_range=0.1, height_shift_range=0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './data-ch20/train',\n",
        "    target_size=(150,150),\n",
        "    batch_size=5,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    './data-ch20/test',\n",
        "    target_size=(150,150),\n",
        "    batch_size=5,\n",
        "    class_mode='binary')\n",
        "\n",
        "transfer_model = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))\n",
        "transfer_model.trainable = False\n",
        "\n",
        "finetune_model = models.Sequential()\n",
        "finetune_model.add(transfer_model)\n",
        "finetune_model.add(Flatten())\n",
        "'''\n",
        "finetune_model.add(Dense(64, activation='relu'))\n",
        "finetune_model.add(Dropout(0.5))\n",
        "finetune_model.add(Dense(1, activation='sigmoid'))\n",
        "'''\n",
        "finetune_model.add(Dense(64))\n",
        "finetune_model.add(Activation('relu'))\n",
        "finetune_model.add(Dropout(0.5))\n",
        "finetune_model.add(Dense(1))\n",
        "finetune_model.add(Activation('sigmoid'))\n",
        "finetune_model.summary()\n",
        "\n",
        "finetune_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "history = finetune_model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=10,\n",
        "    callbacks=[early_stopping_callback])\n",
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
        "\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mDfBRfr4G5cv",
        "outputId": "ced9b9fd-833a-4f20-99e4-37ea8cf4eefc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data-ch20' already exists and is not an empty directory.\n",
            "Found 160 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                524352    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15239105 (58.13 MB)\n",
            "Trainable params: 524417 (2.00 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 46ms/step - loss: 0.7358 - accuracy: 0.5688 - val_loss: 0.5309 - val_accuracy: 0.8000\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.5734 - accuracy: 0.7250 - val_loss: 0.5366 - val_accuracy: 0.7000\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 0.5119 - accuracy: 0.7500 - val_loss: 0.3888 - val_accuracy: 0.9000\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.4513 - accuracy: 0.8062 - val_loss: 0.3741 - val_accuracy: 0.7800\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.3435 - accuracy: 0.8750 - val_loss: 0.2813 - val_accuracy: 0.9400\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.3611 - accuracy: 0.8625 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 1s 44ms/step - loss: 0.3678 - accuracy: 0.8813 - val_loss: 0.2674 - val_accuracy: 0.9400\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.2736 - accuracy: 0.9125 - val_loss: 0.2827 - val_accuracy: 0.9200\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.2472 - accuracy: 0.9375 - val_loss: 0.2236 - val_accuracy: 0.9800\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.2560 - accuracy: 0.9125 - val_loss: 0.2254 - val_accuracy: 0.9000\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.2160 - accuracy: 0.9563 - val_loss: 0.1802 - val_accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.2396 - accuracy: 0.9000 - val_loss: 0.1867 - val_accuracy: 0.9400\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.2049 - accuracy: 0.9375 - val_loss: 0.2206 - val_accuracy: 0.9400\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 0.1876 - accuracy: 0.9438 - val_loss: 0.1987 - val_accuracy: 0.9400\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.1823 - accuracy: 0.9312 - val_loss: 0.1206 - val_accuracy: 0.9600\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 2s 51ms/step - loss: 0.1676 - accuracy: 0.9500 - val_loss: 0.1666 - val_accuracy: 0.9600\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 2s 55ms/step - loss: 0.1804 - accuracy: 0.9438 - val_loss: 0.1920 - val_accuracy: 0.9600\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 1s 41ms/step - loss: 0.1554 - accuracy: 0.9563 - val_loss: 0.1613 - val_accuracy: 0.9200\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.1687 - accuracy: 0.9500 - val_loss: 0.1207 - val_accuracy: 0.9600\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 0.1569 - accuracy: 0.9688 - val_loss: 0.1539 - val_accuracy: 0.9600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}